{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "from collections import deque\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Paperspace/DinoRunTutorial/blob/master/Reinforcement%20Learning%20Dino%20Run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_url = \"chrome://dino\"\n",
    "chrome_driver_path = ChromeDriverManager().install()\n",
    "\n",
    "loss_file_path = \"./objects/loss.csv\"\n",
    "actions_file_path = \"./objects/actions.csv\"\n",
    "q_value_file_path = \"./objects/q_values.csv\"\n",
    "scores_file_path = \"./objects/scores.csv\"\n",
    "\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); return canvasRunner.toDataURL().substring(22)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = process_img(screen)\n",
    "    return image\n",
    "\n",
    "def process_img(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (80, 80))\n",
    "    return image\n",
    "\n",
    "def show_img(graphs = False):\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)\n",
    "        imS = cv2.resize(screen, (800, 400))\n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        service = Service(chrome_driver_path)\n",
    "        self._driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        self._driver.set_window_position(x=300,y=300)\n",
    "        self._driver.set_window_size(900, 600)\n",
    "        \n",
    "        try : \n",
    "            self._driver.get(game_url)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "        \n",
    "    def get_crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element(\"tag name\", \"body\").send_keys(Keys.ARROW_UP)\n",
    "    def press_down(self):\n",
    "        self._driver.find_element(\"tag name\", \"body\").send_keys(Keys.ARROW_DOWN)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array)\n",
    "        return int(score)\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoAgent:\n",
    "    def __init__(self, game):\n",
    "        self._game = game\n",
    "        sleep(1)\n",
    "        self.jump()\n",
    "    def is_running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.get_crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_state:\n",
    "    def __init__(self, agent, game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img()\n",
    "        self._display.__next__()\n",
    "        \n",
    "    def get_state(self, actions):\n",
    "        score = self._game.get_score()\n",
    "        reward = 1\n",
    "        is_over = False\n",
    "        \n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "            reward = -3\n",
    "        \n",
    "        image = grab_screen(self._game._driver)\n",
    "        self._display.send(image)\n",
    "        \n",
    "        if self._agent.is_crashed():\n",
    "            self._game.restart()\n",
    "            reward = -100\n",
    "            is_over = True\n",
    "        \n",
    "        return image, reward, is_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "PRETRAINED = False\n",
    "ACTIONS = 2\n",
    "GAMMA = 0.99\n",
    "OBSERVATION = 100.  # timesteps to observe before training\n",
    "EXPLORE = 100000.  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001  # final value of epsilon\n",
    "INITIAL_EPSILON = 0.01  # starting value of epsilon\n",
    "LEARNING_RATE = 1e-4\n",
    "REPLAY_MEMORY = 50000  # number of previous transitions to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda :  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "print(\"cuda : \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device : \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoNet(nn.Module):\n",
    "    def __init__(self, actions):\n",
    "        super(DinoNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.adv_hid = nn.Linear(64, 64)\n",
    "        self.adv = nn.Linear(64, actions)\n",
    "        self.val_hid = nn.Linear(64, 64)\n",
    "        self.val = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        adv = F.relu(self.adv_hid(x))\n",
    "        adv = self.adv(adv)\n",
    "        val = F.relu(self.val_hid(x))\n",
    "        val = self.val(val)\n",
    "        \n",
    "        q_value = val + adv - adv.mean(dim=1, keepdim=True)\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DinoNet(actions=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# create a new model if not exist\n",
    "if not os.path.isdir(\"./model\"):\n",
    "    os.makedirs(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model.load_state_dict(torch.load(f\"./latest.pth\"))\n",
    "    \n",
    "if PRETRAINED:\n",
    "    load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNetwork(model, game_state, optimizer, loss_fn, num_episodes, batch_size=32):\n",
    "    replay_memory = deque(maxlen=REPLAY_MEMORY)\n",
    "    epsilon = INITIAL_EPSILON\n",
    "    global_step = 0\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        total_loss = 0\n",
    "        total_reward = 0\n",
    "        game_state._game.restart()\n",
    "\n",
    "        # Get initial state\n",
    "        state, reward, done = game_state.get_state([1, 0])  # Start with no action\n",
    "        state = torch.tensor(state, device=device, dtype=torch.float).unsqueeze(0)\n",
    "        \n",
    "        # Reduce epsilon\n",
    "        if episode % 1 == 0:\n",
    "            epsilon = max(FINAL_EPSILON, epsilon - (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE)\n",
    "\n",
    "        while not game_state._agent.is_crashed():\n",
    "            global_step += 1\n",
    "            action = [0, 1] if random.random() <= epsilon else [1, 0]  # Random or best action based on epsilon\n",
    "            next_state, reward, done = game_state.get_state(action)\n",
    "            next_state = torch.tensor(next_state, device=device, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "            # Save transition to replay memory\n",
    "            replay_memory.append((state, action, reward, next_state, done))\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            # Check if the memory is sufficient to sample from\n",
    "            if len(replay_memory) >= batch_size:\n",
    "                # Sample a minibatch from replay memory\n",
    "                minibatch = random.sample(replay_memory, batch_size)\n",
    "                state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*minibatch)\n",
    "\n",
    "                state_batch = torch.stack(state_batch)\n",
    "                next_state_batch = torch.stack(next_state_batch)\n",
    "                reward_batch = torch.tensor(reward_batch, device=device, dtype=torch.float)\n",
    "                action_batch = torch.tensor([a.index(1) for a in action_batch], device=device, dtype=torch.long).unsqueeze(1)\n",
    "                done_batch = torch.tensor(done_batch, device=device, dtype=torch.float)\n",
    "\n",
    "                # Compute Q(s_t, a)\n",
    "                current_q_values = model(state_batch).gather(1, action_batch)\n",
    "\n",
    "                # Compute Q(s_t+1) for all next states.\n",
    "                next_q_values = model(next_state_batch).max(1)[0]\n",
    "                # Compute the target Q values\n",
    "                target_q_values = reward_batch + (GAMMA * next_q_values * (1 - done_batch))\n",
    "\n",
    "                # Compute Bellman error\n",
    "                loss = loss_fn(current_q_values.squeeze(1), target_q_values.detach())\n",
    "\n",
    "                # Optimize the model\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                print(f\"g_step: {global_step}, action: {np.argmax(action)}, reward: {reward}, loss: {loss.item()}\")\n",
    "\n",
    "            sleep(0.05)  # Sleep to decrease the speed of execution\n",
    "\n",
    "        print(f\"Episode {episode + 1}, Total reward: {total_reward}, Total loss: {total_loss}, Epsilon: {epsilon}\")\n",
    "\n",
    "        # Optionally save the model\n",
    "        if episode % 10 == 0:\n",
    "            torch.save(model.state_dict(), f\"./model/dino_net_{episode}.pth\")\n",
    "\n",
    "    # Save the final model\n",
    "    torch.save(model.state_dict(), \"./model/dino_net_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playGame():\n",
    "    game = Game()\n",
    "    dino = DinoAgent(game)\n",
    "    game_state = Game_state(dino, game)\n",
    "    try :\n",
    "        trainNetwork(model, game_state, optimizer, loss_fn, num_episodes=1000)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_step: 32, action: 0, reward: 1, loss: 2.500885009765625\n",
      "Episode 1, Total reward: 32, Total loss: 2.500885009765625, Epsilon: 0.009999901\n",
      "g_step: 33, action: 0, reward: 1, loss: 2.023440361022949\n",
      "g_step: 34, action: 0, reward: 1, loss: 1.6406183242797852\n",
      "g_step: 35, action: 0, reward: 1, loss: 1.4479327201843262\n",
      "g_step: 36, action: 0, reward: 1, loss: 1.2986059188842773\n",
      "g_step: 37, action: 0, reward: 1, loss: 1.1987905502319336\n",
      "g_step: 38, action: 0, reward: 1, loss: 1.1500740051269531\n",
      "g_step: 39, action: 0, reward: 1, loss: 1.2284672260284424\n",
      "g_step: 40, action: 0, reward: 1, loss: 1.1804471015930176\n",
      "g_step: 41, action: 0, reward: 1, loss: 1.1831492185592651\n",
      "g_step: 42, action: 0, reward: 1, loss: 1.2884538173675537\n",
      "g_step: 43, action: 0, reward: 1, loss: 1.2667040824890137\n",
      "g_step: 44, action: 0, reward: 1, loss: 1.2824392318725586\n",
      "g_step: 45, action: 0, reward: 1, loss: 1.1499900817871094\n",
      "g_step: 46, action: 0, reward: 1, loss: 0.9541349411010742\n",
      "g_step: 47, action: 0, reward: 1, loss: 1.2480236291885376\n",
      "g_step: 48, action: 0, reward: 1, loss: 1.0618972778320312\n",
      "g_step: 49, action: 0, reward: 1, loss: 1.2881181240081787\n",
      "g_step: 50, action: 0, reward: 1, loss: 1.3529205322265625\n",
      "g_step: 51, action: 0, reward: 1, loss: 1.1874966621398926\n",
      "g_step: 52, action: 0, reward: 1, loss: 1.3377933502197266\n",
      "g_step: 53, action: 0, reward: 1, loss: 1.575118899345398\n",
      "g_step: 54, action: 0, reward: 1, loss: 1.8438385725021362\n",
      "g_step: 55, action: 0, reward: 1, loss: 1.4834799766540527\n",
      "g_step: 56, action: 0, reward: 1, loss: 1.8773882389068604\n",
      "g_step: 57, action: 0, reward: 1, loss: 1.4229168891906738\n",
      "g_step: 58, action: 0, reward: 1, loss: 1.4159135818481445\n",
      "g_step: 59, action: 0, reward: 1, loss: 1.8166406154632568\n",
      "g_step: 60, action: 0, reward: 1, loss: 1.2676377296447754\n",
      "g_step: 61, action: 0, reward: 1, loss: 1.4295437335968018\n",
      "g_step: 62, action: 0, reward: 1, loss: 1.8689463138580322\n",
      "g_step: 63, action: 0, reward: 1, loss: 2.033919095993042\n",
      "g_step: 64, action: 0, reward: 1, loss: 2.5180728435516357\n",
      "g_step: 65, action: 0, reward: 1, loss: 1.4483892917633057\n",
      "g_step: 66, action: 0, reward: 1, loss: 1.9484938383102417\n",
      "g_step: 67, action: 0, reward: 1, loss: 2.076465129852295\n",
      "g_step: 68, action: 0, reward: 1, loss: 2.9529380798339844\n",
      "g_step: 69, action: 0, reward: 1, loss: 2.8131818771362305\n",
      "g_step: 70, action: 0, reward: 1, loss: 3.0873970985412598\n",
      "g_step: 71, action: 0, reward: 1, loss: 1.8602179288864136\n",
      "g_step: 72, action: 0, reward: 1, loss: 2.9777395725250244\n",
      "g_step: 73, action: 0, reward: 1, loss: 2.0814149379730225\n",
      "g_step: 74, action: 0, reward: 1, loss: 3.540329933166504\n",
      "g_step: 75, action: 0, reward: 1, loss: 3.649348020553589\n",
      "g_step: 76, action: 0, reward: 1, loss: 4.473426818847656\n",
      "g_step: 77, action: 0, reward: 1, loss: 4.545247554779053\n",
      "g_step: 78, action: 0, reward: 1, loss: 4.531129837036133\n",
      "g_step: 79, action: 0, reward: 1, loss: 6.2819061279296875\n",
      "g_step: 80, action: 0, reward: 1, loss: 7.398299217224121\n",
      "g_step: 81, action: 0, reward: 1, loss: 6.7027130126953125\n",
      "g_step: 82, action: 0, reward: 1, loss: 6.775790691375732\n",
      "g_step: 83, action: 0, reward: 1, loss: 9.387055397033691\n",
      "g_step: 84, action: 0, reward: 1, loss: 12.864972114562988\n",
      "g_step: 85, action: 0, reward: 1, loss: 12.562996864318848\n",
      "g_step: 86, action: 0, reward: 1, loss: 10.061992645263672\n",
      "g_step: 87, action: 0, reward: 1, loss: 14.476920127868652\n",
      "g_step: 88, action: 0, reward: 1, loss: 16.186357498168945\n",
      "g_step: 89, action: 0, reward: 1, loss: 21.907339096069336\n",
      "g_step: 90, action: 0, reward: 1, loss: 16.827497482299805\n",
      "g_step: 91, action: 0, reward: 1, loss: 28.195453643798828\n",
      "g_step: 92, action: 0, reward: -100, loss: 35.658843994140625\n",
      "g_step: 93, action: 0, reward: 1, loss: 1481.10107421875\n",
      "g_step: 94, action: 0, reward: 1, loss: 41.35547637939453\n",
      "g_step: 95, action: 0, reward: 1, loss: 35.588218688964844\n",
      "g_step: 96, action: 0, reward: 1, loss: 1436.2645263671875\n",
      "g_step: 97, action: 0, reward: 1, loss: 48.430763244628906\n",
      "g_step: 98, action: 0, reward: 1, loss: 38.289432525634766\n",
      "g_step: 99, action: 0, reward: 1, loss: 34.61431884765625\n",
      "g_step: 100, action: 0, reward: 1, loss: 28.932979583740234\n",
      "g_step: 101, action: 0, reward: 1, loss: 1306.9984130859375\n",
      "g_step: 102, action: 0, reward: 1, loss: 35.3140983581543\n",
      "g_step: 103, action: 0, reward: 1, loss: 30.653827667236328\n",
      "g_step: 104, action: 0, reward: 1, loss: 35.55097961425781\n",
      "g_step: 105, action: 0, reward: 1, loss: 20.430343627929688\n",
      "g_step: 106, action: 0, reward: 1, loss: 28.75560760498047\n",
      "g_step: 107, action: 0, reward: 1, loss: 34.62392044067383\n",
      "g_step: 108, action: 0, reward: 1, loss: 28.515972137451172\n",
      "g_step: 109, action: 0, reward: 1, loss: 39.632225036621094\n",
      "g_step: 110, action: 0, reward: 1, loss: 1129.477783203125\n",
      "g_step: 111, action: 0, reward: 1, loss: 1103.6131591796875\n",
      "g_step: 112, action: 0, reward: 1, loss: 16.51677703857422\n",
      "g_step: 113, action: 0, reward: 1, loss: 12.266695022583008\n",
      "g_step: 114, action: 0, reward: 1, loss: 1006.6283569335938\n",
      "g_step: 115, action: 0, reward: 1, loss: 32.57530212402344\n",
      "g_step: 116, action: 0, reward: 1, loss: 18.763660430908203\n",
      "g_step: 117, action: 0, reward: 1, loss: 908.36865234375\n",
      "g_step: 118, action: 0, reward: 1, loss: 17.867305755615234\n",
      "g_step: 119, action: 0, reward: 1, loss: 17.529876708984375\n",
      "g_step: 120, action: 0, reward: 1, loss: 23.783626556396484\n",
      "g_step: 121, action: 0, reward: 1, loss: 25.38393783569336\n",
      "g_step: 122, action: 0, reward: 1, loss: 21.7546443939209\n",
      "g_step: 123, action: 0, reward: 1, loss: 14.70761489868164\n",
      "g_step: 124, action: 0, reward: 1, loss: 13.302677154541016\n",
      "g_step: 125, action: 0, reward: 1, loss: 15.619394302368164\n",
      "g_step: 126, action: 0, reward: 1, loss: 19.87176513671875\n",
      "g_step: 127, action: 0, reward: 1, loss: 18.806232452392578\n",
      "g_step: 128, action: 0, reward: 1, loss: 679.1565551757812\n",
      "g_step: 129, action: 0, reward: 1, loss: 9.748800277709961\n",
      "g_step: 130, action: 0, reward: 1, loss: 654.0885620117188\n",
      "g_step: 131, action: 0, reward: 1, loss: 11.372859954833984\n",
      "g_step: 132, action: 0, reward: 1, loss: 636.2874755859375\n",
      "g_step: 133, action: 0, reward: 1, loss: 16.98603057861328\n",
      "g_step: 134, action: 0, reward: 1, loss: 21.788700103759766\n",
      "g_step: 135, action: 0, reward: 1, loss: 17.84975242614746\n",
      "g_step: 136, action: 0, reward: 1, loss: 14.633065223693848\n",
      "g_step: 137, action: 0, reward: 1, loss: 17.23468780517578\n",
      "g_step: 138, action: 0, reward: 1, loss: 14.320234298706055\n",
      "g_step: 139, action: 0, reward: 1, loss: 17.6651611328125\n",
      "g_step: 140, action: 0, reward: 1, loss: 10.735867500305176\n",
      "g_step: 141, action: 0, reward: 1, loss: 17.747283935546875\n",
      "g_step: 142, action: 0, reward: 1, loss: 13.307158470153809\n",
      "g_step: 143, action: 0, reward: 1, loss: 14.632728576660156\n",
      "g_step: 144, action: 0, reward: 1, loss: 21.01483154296875\n",
      "g_step: 145, action: 0, reward: 1, loss: 16.894916534423828\n",
      "g_step: 146, action: 0, reward: 1, loss: 543.4575805664062\n",
      "g_step: 147, action: 0, reward: 1, loss: 20.78789710998535\n",
      "g_step: 148, action: 0, reward: 1, loss: 16.17552947998047\n",
      "g_step: 149, action: 0, reward: 1, loss: 22.430988311767578\n",
      "g_step: 150, action: 0, reward: 1, loss: 537.0176391601562\n",
      "Episode 2, Total reward: 17, Total loss: 12760.820716142654, Epsilon: 0.009999802\n",
      "g_step: 151, action: 0, reward: 1, loss: 22.85334587097168\n",
      "g_step: 152, action: 0, reward: 1, loss: 21.109710693359375\n",
      "g_step: 153, action: 0, reward: 1, loss: 20.091949462890625\n",
      "g_step: 154, action: 0, reward: 1, loss: 25.100399017333984\n",
      "g_step: 155, action: 0, reward: 1, loss: 505.75830078125\n",
      "g_step: 156, action: 0, reward: 1, loss: 25.34203338623047\n",
      "g_step: 157, action: 0, reward: 1, loss: 506.0262145996094\n",
      "g_step: 158, action: 0, reward: 1, loss: 16.502838134765625\n",
      "g_step: 159, action: 0, reward: 1, loss: 14.376413345336914\n",
      "g_step: 160, action: 0, reward: 1, loss: 15.17408275604248\n",
      "g_step: 161, action: 0, reward: 1, loss: 36.919620513916016\n",
      "g_step: 162, action: 0, reward: 1, loss: 472.1426086425781\n",
      "g_step: 163, action: 0, reward: 1, loss: 21.108383178710938\n",
      "g_step: 164, action: 0, reward: 1, loss: 15.23009204864502\n",
      "g_step: 165, action: 0, reward: 1, loss: 16.32263946533203\n",
      "g_step: 166, action: 0, reward: 1, loss: 18.580516815185547\n",
      "g_step: 167, action: 0, reward: 1, loss: 21.763214111328125\n",
      "g_step: 168, action: 0, reward: 1, loss: 22.850910186767578\n",
      "g_step: 169, action: 0, reward: 1, loss: 28.20069122314453\n",
      "g_step: 170, action: 0, reward: 1, loss: 452.70703125\n",
      "g_step: 171, action: 0, reward: 1, loss: 14.533098220825195\n",
      "g_step: 172, action: 0, reward: 1, loss: 31.252735137939453\n",
      "g_step: 173, action: 0, reward: 1, loss: 435.5368957519531\n",
      "g_step: 174, action: 0, reward: 1, loss: 20.784263610839844\n",
      "g_step: 175, action: 0, reward: 1, loss: 428.4644470214844\n",
      "g_step: 176, action: 0, reward: 1, loss: 24.05436134338379\n",
      "g_step: 177, action: 0, reward: 1, loss: 19.05086898803711\n",
      "g_step: 178, action: 0, reward: 1, loss: 17.514217376708984\n",
      "g_step: 179, action: 0, reward: 1, loss: 26.146156311035156\n",
      "g_step: 180, action: 0, reward: 1, loss: 19.241458892822266\n",
      "g_step: 181, action: 0, reward: 1, loss: 21.83182144165039\n",
      "g_step: 182, action: 0, reward: 1, loss: 40.9084358215332\n",
      "g_step: 183, action: 0, reward: 1, loss: 29.391754150390625\n",
      "g_step: 184, action: 0, reward: 1, loss: 37.83856201171875\n",
      "g_step: 185, action: 0, reward: 1, loss: 23.892654418945312\n",
      "g_step: 186, action: 0, reward: 1, loss: 390.0859375\n",
      "g_step: 187, action: 0, reward: 1, loss: 24.5587158203125\n",
      "g_step: 188, action: 0, reward: 1, loss: 17.98939323425293\n",
      "g_step: 189, action: 0, reward: 1, loss: 11.709139823913574\n",
      "g_step: 190, action: 0, reward: 1, loss: 27.134868621826172\n",
      "g_step: 191, action: 0, reward: 1, loss: 16.497175216674805\n",
      "g_step: 192, action: 0, reward: 1, loss: 19.326059341430664\n",
      "g_step: 193, action: 0, reward: 1, loss: 27.852420806884766\n",
      "g_step: 194, action: 0, reward: 1, loss: 22.512401580810547\n",
      "g_step: 195, action: 0, reward: 1, loss: 23.751441955566406\n",
      "g_step: 196, action: 0, reward: 1, loss: 15.431497573852539\n",
      "g_step: 197, action: 0, reward: 1, loss: 14.045243263244629\n",
      "g_step: 198, action: 0, reward: 1, loss: 28.967592239379883\n",
      "g_step: 199, action: 0, reward: 1, loss: 23.27732276916504\n",
      "g_step: 200, action: 0, reward: 1, loss: 22.246723175048828\n",
      "g_step: 201, action: 0, reward: 1, loss: 24.40204429626465\n",
      "g_step: 202, action: 0, reward: 1, loss: 23.819726943969727\n",
      "g_step: 203, action: 0, reward: 1, loss: 19.882076263427734\n",
      "g_step: 204, action: 0, reward: 1, loss: 26.560916900634766\n",
      "g_step: 205, action: 0, reward: 1, loss: 37.63554763793945\n",
      "g_step: 206, action: 0, reward: 1, loss: 398.5121765136719\n",
      "g_step: 207, action: 0, reward: 1, loss: 397.9657897949219\n",
      "g_step: 208, action: 0, reward: 1, loss: 21.01764678955078\n",
      "g_step: 209, action: 0, reward: 1, loss: 21.689546585083008\n",
      "Episode 3, Total reward: 59, Total loss: 5125.474130630493, Epsilon: 0.009999703\n",
      "g_step: 210, action: 0, reward: 1, loss: 387.0670166015625\n",
      "g_step: 211, action: 0, reward: 1, loss: 30.711578369140625\n",
      "g_step: 212, action: 0, reward: 1, loss: 18.256357192993164\n",
      "g_step: 213, action: 0, reward: 1, loss: 21.926151275634766\n",
      "g_step: 214, action: 0, reward: 1, loss: 24.786907196044922\n",
      "g_step: 215, action: 0, reward: 1, loss: 28.267227172851562\n",
      "g_step: 216, action: 0, reward: 1, loss: 19.18323516845703\n",
      "g_step: 217, action: 0, reward: 1, loss: 14.622244834899902\n",
      "g_step: 218, action: 0, reward: 1, loss: 19.74489974975586\n",
      "g_step: 219, action: 0, reward: 1, loss: 21.491497039794922\n",
      "g_step: 220, action: 0, reward: 1, loss: 30.0185489654541\n",
      "g_step: 221, action: 0, reward: 1, loss: 28.86144256591797\n",
      "g_step: 222, action: 0, reward: 1, loss: 15.799653053283691\n",
      "g_step: 223, action: 0, reward: 1, loss: 18.499496459960938\n",
      "g_step: 224, action: 0, reward: 1, loss: 18.254653930664062\n",
      "g_step: 225, action: 0, reward: 1, loss: 347.01171875\n",
      "g_step: 226, action: 0, reward: 1, loss: 26.19805908203125\n",
      "g_step: 227, action: 0, reward: 1, loss: 16.32477378845215\n",
      "g_step: 228, action: 0, reward: 1, loss: 22.011110305786133\n",
      "g_step: 229, action: 0, reward: 1, loss: 17.435710906982422\n",
      "g_step: 230, action: 0, reward: 1, loss: 21.87311363220215\n",
      "g_step: 231, action: 0, reward: 1, loss: 20.544879913330078\n",
      "g_step: 232, action: 0, reward: 1, loss: 328.8158264160156\n",
      "g_step: 233, action: 0, reward: 1, loss: 24.87245750427246\n",
      "g_step: 234, action: 0, reward: 1, loss: 17.498659133911133\n",
      "g_step: 235, action: 0, reward: 1, loss: 23.37812042236328\n",
      "g_step: 236, action: 0, reward: 1, loss: 24.21107292175293\n",
      "g_step: 237, action: 0, reward: 1, loss: 30.066234588623047\n",
      "g_step: 238, action: 0, reward: 1, loss: 22.25232696533203\n",
      "g_step: 239, action: 0, reward: 1, loss: 16.526288986206055\n",
      "g_step: 240, action: 0, reward: 1, loss: 21.328548431396484\n",
      "g_step: 241, action: 0, reward: 1, loss: 21.202743530273438\n",
      "g_step: 242, action: 0, reward: 1, loss: 16.253549575805664\n",
      "g_step: 243, action: 0, reward: 1, loss: 20.705198287963867\n",
      "g_step: 244, action: 0, reward: 1, loss: 26.74373435974121\n",
      "g_step: 245, action: 0, reward: 1, loss: 33.49787521362305\n",
      "g_step: 246, action: 0, reward: 1, loss: 31.328310012817383\n",
      "g_step: 247, action: 0, reward: 1, loss: 23.536378860473633\n",
      "g_step: 248, action: 0, reward: 1, loss: 13.278105735778809\n",
      "g_step: 249, action: 0, reward: 1, loss: 17.69302749633789\n",
      "g_step: 250, action: 0, reward: 1, loss: 18.277307510375977\n",
      "g_step: 251, action: 0, reward: 1, loss: 19.52722930908203\n",
      "g_step: 252, action: 0, reward: 1, loss: 19.564006805419922\n",
      "g_step: 253, action: 0, reward: 1, loss: 23.37654685974121\n",
      "g_step: 254, action: 0, reward: 1, loss: 24.7501163482666\n",
      "g_step: 255, action: 0, reward: 1, loss: 27.407634735107422\n",
      "g_step: 256, action: 0, reward: 1, loss: 319.0401916503906\n",
      "g_step: 257, action: 0, reward: 1, loss: 313.08380126953125\n",
      "g_step: 258, action: 0, reward: 1, loss: 27.897113800048828\n",
      "g_step: 259, action: 0, reward: 1, loss: 29.291481018066406\n",
      "g_step: 260, action: 0, reward: 1, loss: 15.2283935546875\n",
      "g_step: 261, action: 0, reward: 1, loss: 31.359477996826172\n",
      "g_step: 262, action: 0, reward: 1, loss: 19.221649169921875\n",
      "g_step: 263, action: 0, reward: 1, loss: 20.870418548583984\n",
      "g_step: 264, action: 0, reward: 1, loss: 271.20806884765625\n",
      "g_step: 265, action: 0, reward: 1, loss: 267.66351318359375\n",
      "g_step: 266, action: 0, reward: 1, loss: 22.96593475341797\n",
      "g_step: 267, action: 0, reward: 1, loss: 14.7207670211792\n",
      "g_step: 268, action: 0, reward: 1, loss: 15.673517227172852\n",
      "g_step: 269, action: 0, reward: -100, loss: 33.36094665527344\n",
      "g_step: 270, action: 0, reward: 1, loss: 15.108926773071289\n",
      "g_step: 271, action: 0, reward: 1, loss: 14.915738105773926\n",
      "g_step: 272, action: 0, reward: 1, loss: 444.08642578125\n",
      "g_step: 273, action: 0, reward: 1, loss: 25.612960815429688\n",
      "g_step: 274, action: 0, reward: 1, loss: 231.50741577148438\n",
      "g_step: 275, action: 0, reward: 1, loss: 18.010051727294922\n",
      "g_step: 276, action: 0, reward: 1, loss: 14.86673355102539\n",
      "g_step: 277, action: 1, reward: -3, loss: 50.345054626464844\n",
      "g_step: 278, action: 0, reward: 1, loss: 50.699363708496094\n",
      "g_step: 279, action: 0, reward: 1, loss: 17.237674713134766\n",
      "g_step: 280, action: 0, reward: 1, loss: 53.62217712402344\n",
      "g_step: 281, action: 0, reward: 1, loss: 25.599166870117188\n",
      "g_step: 282, action: 0, reward: 1, loss: 375.9891662597656\n",
      "g_step: 283, action: 0, reward: 1, loss: 42.66753387451172\n",
      "g_step: 284, action: 0, reward: 1, loss: 54.85386276245117\n",
      "g_step: 285, action: 0, reward: 1, loss: 24.74766731262207\n",
      "g_step: 286, action: 0, reward: 1, loss: 217.08847045898438\n",
      "g_step: 287, action: 0, reward: 1, loss: 47.24021911621094\n",
      "g_step: 288, action: 0, reward: 1, loss: 19.96622657775879\n",
      "g_step: 289, action: 0, reward: 1, loss: 334.09033203125\n",
      "g_step: 290, action: 0, reward: 1, loss: 22.527725219726562\n",
      "g_step: 291, action: 0, reward: 1, loss: 17.62160301208496\n",
      "g_step: 292, action: 0, reward: 1, loss: 13.415021896362305\n",
      "g_step: 293, action: 0, reward: 1, loss: 20.786636352539062\n",
      "g_step: 294, action: 0, reward: 1, loss: 24.554393768310547\n",
      "g_step: 295, action: 0, reward: 1, loss: 38.12241744995117\n",
      "g_step: 296, action: 0, reward: 1, loss: 21.805110931396484\n",
      "g_step: 297, action: 0, reward: 1, loss: 59.78937530517578\n",
      "g_step: 298, action: 0, reward: 1, loss: 27.170785903930664\n",
      "g_step: 299, action: 0, reward: 1, loss: 450.00152587890625\n",
      "g_step: 300, action: 0, reward: 1, loss: 16.315933227539062\n",
      "g_step: 301, action: 0, reward: 1, loss: 21.013408660888672\n",
      "g_step: 302, action: 0, reward: 1, loss: 36.78962707519531\n",
      "g_step: 303, action: 0, reward: 1, loss: 26.580169677734375\n",
      "g_step: 304, action: 0, reward: 1, loss: 21.10997772216797\n",
      "g_step: 305, action: 0, reward: 1, loss: 39.83180236816406\n",
      "g_step: 306, action: 0, reward: 1, loss: 19.641128540039062\n",
      "g_step: 307, action: 0, reward: 1, loss: 64.34414672851562\n",
      "g_step: 308, action: 0, reward: 1, loss: 304.8834533691406\n",
      "g_step: 309, action: 0, reward: 1, loss: 17.91222381591797\n",
      "g_step: 310, action: 0, reward: 1, loss: 15.966508865356445\n",
      "g_step: 311, action: 0, reward: 1, loss: 23.42331314086914\n",
      "g_step: 312, action: 0, reward: 1, loss: 24.325122833251953\n",
      "g_step: 313, action: 0, reward: 1, loss: 16.575855255126953\n",
      "g_step: 314, action: 0, reward: 1, loss: 28.640403747558594\n",
      "g_step: 315, action: 0, reward: 1, loss: 18.672443389892578\n",
      "g_step: 316, action: 0, reward: 1, loss: 63.11033630371094\n",
      "g_step: 317, action: 0, reward: 1, loss: 54.460758209228516\n",
      "g_step: 318, action: 0, reward: 1, loss: 196.67965698242188\n",
      "g_step: 319, action: 0, reward: 1, loss: 55.3037109375\n",
      "g_step: 320, action: 0, reward: 1, loss: 22.26095962524414\n",
      "g_step: 321, action: 0, reward: 1, loss: 20.438587188720703\n",
      "g_step: 322, action: 0, reward: 1, loss: 24.02112579345703\n",
      "g_step: 323, action: 0, reward: 1, loss: 50.86719512939453\n",
      "g_step: 324, action: 0, reward: 1, loss: 32.02597427368164\n",
      "g_step: 325, action: 0, reward: 1, loss: 261.3650207519531\n",
      "g_step: 326, action: 0, reward: 1, loss: 241.17886352539062\n",
      "g_step: 327, action: 0, reward: 1, loss: 21.509944915771484\n",
      "g_step: 328, action: 0, reward: 1, loss: 45.62772750854492\n",
      "g_step: 329, action: 0, reward: 1, loss: 209.09654235839844\n",
      "g_step: 330, action: 0, reward: 1, loss: 37.3807373046875\n",
      "g_step: 331, action: 0, reward: 1, loss: 10.287332534790039\n",
      "g_step: 332, action: 0, reward: 1, loss: 24.394662857055664\n",
      "g_step: 333, action: 0, reward: 1, loss: 182.55618286132812\n",
      "g_step: 334, action: 0, reward: 1, loss: 30.881473541259766\n",
      "g_step: 335, action: 0, reward: 1, loss: 22.477294921875\n",
      "g_step: 336, action: 0, reward: 1, loss: 56.111228942871094\n",
      "g_step: 337, action: 0, reward: 1, loss: 17.111431121826172\n",
      "g_step: 338, action: 0, reward: 1, loss: 28.146678924560547\n",
      "g_step: 339, action: 0, reward: 1, loss: 19.98832130432129\n",
      "g_step: 340, action: 0, reward: 1, loss: 33.91816711425781\n",
      "g_step: 341, action: 0, reward: 1, loss: 229.02029418945312\n",
      "g_step: 342, action: 0, reward: 1, loss: 40.27705383300781\n",
      "Episode 4, Total reward: 28, Total loss: 8917.139395713806, Epsilon: 0.009999604\n",
      "g_step: 343, action: 0, reward: 1, loss: 37.96454620361328\n",
      "g_step: 344, action: 0, reward: 1, loss: 30.518150329589844\n",
      "g_step: 345, action: 0, reward: 1, loss: 18.72732162475586\n",
      "g_step: 346, action: 0, reward: 1, loss: 35.920188903808594\n",
      "g_step: 347, action: 0, reward: 1, loss: 24.185794830322266\n",
      "g_step: 348, action: 0, reward: 1, loss: 197.7194366455078\n",
      "g_step: 349, action: 0, reward: 1, loss: 48.75952911376953\n",
      "g_step: 350, action: 0, reward: 1, loss: 26.02880096435547\n",
      "g_step: 351, action: 0, reward: 1, loss: 210.41561889648438\n",
      "g_step: 352, action: 0, reward: 1, loss: 24.048219680786133\n",
      "g_step: 353, action: 0, reward: 1, loss: 27.027437210083008\n",
      "g_step: 354, action: 0, reward: 1, loss: 31.504554748535156\n",
      "g_step: 355, action: 0, reward: 1, loss: 46.651329040527344\n",
      "g_step: 356, action: 0, reward: 1, loss: 17.075519561767578\n",
      "g_step: 357, action: 0, reward: 1, loss: 28.913944244384766\n",
      "g_step: 358, action: 0, reward: 1, loss: 19.467708587646484\n",
      "g_step: 359, action: 0, reward: 1, loss: 12.150026321411133\n",
      "g_step: 360, action: 0, reward: 1, loss: 14.177587509155273\n",
      "g_step: 361, action: 0, reward: 1, loss: 19.457189559936523\n",
      "g_step: 362, action: 0, reward: 1, loss: 14.441887855529785\n",
      "g_step: 363, action: 0, reward: 1, loss: 235.10552978515625\n",
      "g_step: 364, action: 0, reward: 1, loss: 36.640159606933594\n",
      "g_step: 365, action: 0, reward: 1, loss: 16.58687973022461\n",
      "g_step: 366, action: 0, reward: 1, loss: 12.463634490966797\n",
      "g_step: 367, action: 0, reward: 1, loss: 9.042478561401367\n",
      "g_step: 368, action: 0, reward: 1, loss: 16.342287063598633\n",
      "g_step: 369, action: 0, reward: 1, loss: 26.572402954101562\n",
      "g_step: 370, action: 0, reward: 1, loss: 11.890263557434082\n",
      "g_step: 371, action: 0, reward: 1, loss: 36.932281494140625\n",
      "g_step: 372, action: 0, reward: 1, loss: 23.940532684326172\n",
      "g_step: 373, action: 0, reward: 1, loss: 27.978076934814453\n",
      "g_step: 374, action: 0, reward: 1, loss: 27.23290252685547\n",
      "g_step: 375, action: 0, reward: 1, loss: 21.536640167236328\n",
      "g_step: 376, action: 0, reward: 1, loss: 29.945262908935547\n",
      "g_step: 377, action: 0, reward: 1, loss: 17.440420150756836\n",
      "g_step: 378, action: 0, reward: 1, loss: 24.329479217529297\n",
      "g_step: 379, action: 0, reward: 1, loss: 21.566675186157227\n",
      "g_step: 380, action: 0, reward: 1, loss: 17.114219665527344\n",
      "g_step: 381, action: 0, reward: 1, loss: 199.49822998046875\n",
      "g_step: 382, action: 0, reward: 1, loss: 19.626951217651367\n",
      "g_step: 383, action: 0, reward: 1, loss: 29.129283905029297\n",
      "g_step: 384, action: 0, reward: 1, loss: 9.204994201660156\n",
      "g_step: 385, action: 0, reward: 1, loss: 14.185646057128906\n",
      "g_step: 386, action: 0, reward: 1, loss: 19.140979766845703\n",
      "g_step: 387, action: 0, reward: 1, loss: 20.944538116455078\n",
      "g_step: 388, action: 0, reward: 1, loss: 11.916319847106934\n",
      "g_step: 389, action: 0, reward: 1, loss: 17.790508270263672\n",
      "g_step: 390, action: 0, reward: 1, loss: 194.4175567626953\n",
      "g_step: 391, action: 0, reward: 1, loss: 20.855972290039062\n",
      "g_step: 392, action: 0, reward: 1, loss: 235.7200469970703\n",
      "g_step: 393, action: 0, reward: 1, loss: 21.74032974243164\n",
      "g_step: 394, action: 0, reward: 1, loss: 30.171720504760742\n",
      "g_step: 395, action: 0, reward: 1, loss: 24.26630401611328\n",
      "g_step: 396, action: 0, reward: 1, loss: 211.8896942138672\n",
      "g_step: 397, action: 0, reward: 1, loss: 27.731719970703125\n",
      "g_step: 398, action: 0, reward: 1, loss: 204.9839324951172\n",
      "g_step: 399, action: 0, reward: 1, loss: 15.695796966552734\n",
      "g_step: 400, action: 0, reward: 1, loss: 21.320755004882812\n",
      "g_step: 401, action: 0, reward: -100, loss: 15.126112937927246\n",
      "g_step: 402, action: 0, reward: 1, loss: 14.511850357055664\n",
      "g_step: 403, action: 0, reward: 1, loss: 538.2849731445312\n",
      "g_step: 404, action: 0, reward: 1, loss: 19.17181396484375\n",
      "g_step: 405, action: 0, reward: 1, loss: 16.473541259765625\n",
      "g_step: 406, action: 0, reward: 1, loss: 23.50439453125\n",
      "g_step: 407, action: 0, reward: 1, loss: 5.726507186889648\n",
      "g_step: 408, action: 0, reward: 1, loss: 18.900714874267578\n",
      "g_step: 409, action: 0, reward: 1, loss: 43.34245300292969\n",
      "g_step: 410, action: 0, reward: 1, loss: 135.53431701660156\n",
      "g_step: 411, action: 0, reward: 1, loss: 16.143577575683594\n",
      "g_step: 412, action: 0, reward: 1, loss: 47.33562469482422\n",
      "g_step: 413, action: 0, reward: 1, loss: 8.533875465393066\n",
      "g_step: 414, action: 0, reward: 1, loss: 28.662723541259766\n",
      "g_step: 415, action: 0, reward: 1, loss: 29.40744972229004\n",
      "g_step: 416, action: 0, reward: 1, loss: 15.568987846374512\n",
      "g_step: 417, action: 0, reward: 1, loss: 168.1755828857422\n",
      "g_step: 418, action: 0, reward: 1, loss: 64.37783813476562\n",
      "g_step: 419, action: 0, reward: 1, loss: 154.4962615966797\n",
      "g_step: 420, action: 0, reward: 1, loss: 11.509340286254883\n",
      "g_step: 421, action: 0, reward: 1, loss: 20.372943878173828\n",
      "g_step: 422, action: 0, reward: 1, loss: 64.57817077636719\n",
      "g_step: 423, action: 0, reward: 1, loss: 29.840530395507812\n",
      "g_step: 424, action: 0, reward: 1, loss: 53.07329177856445\n",
      "g_step: 425, action: 0, reward: 1, loss: 28.16144561767578\n",
      "g_step: 426, action: 0, reward: 1, loss: 57.767333984375\n",
      "g_step: 427, action: 0, reward: 1, loss: 13.228799819946289\n",
      "g_step: 428, action: 0, reward: 1, loss: 12.332250595092773\n",
      "g_step: 429, action: 0, reward: 1, loss: 491.69830322265625\n",
      "g_step: 430, action: 0, reward: 1, loss: 17.596633911132812\n",
      "g_step: 431, action: 0, reward: 1, loss: 31.53441619873047\n",
      "g_step: 432, action: 0, reward: 1, loss: 12.038698196411133\n",
      "g_step: 433, action: 0, reward: 1, loss: 284.3501892089844\n",
      "g_step: 434, action: 0, reward: 1, loss: 456.21697998046875\n",
      "g_step: 435, action: 0, reward: 1, loss: 13.244077682495117\n",
      "g_step: 436, action: 0, reward: 1, loss: 28.56557273864746\n",
      "g_step: 437, action: 0, reward: 1, loss: 23.911102294921875\n",
      "g_step: 438, action: 0, reward: 1, loss: 28.370315551757812\n",
      "g_step: 439, action: 0, reward: 1, loss: 15.374883651733398\n",
      "g_step: 440, action: 0, reward: 1, loss: 18.867210388183594\n",
      "g_step: 441, action: 0, reward: 1, loss: 121.44007110595703\n",
      "g_step: 442, action: 0, reward: 1, loss: 116.9500961303711\n",
      "g_step: 443, action: 0, reward: 1, loss: 55.39179611206055\n",
      "g_step: 444, action: 0, reward: 1, loss: 16.496341705322266\n",
      "g_step: 445, action: 0, reward: 1, loss: 237.14393615722656\n",
      "g_step: 446, action: 0, reward: 1, loss: 139.9105682373047\n",
      "g_step: 447, action: 0, reward: 1, loss: 20.34397315979004\n",
      "g_step: 448, action: 0, reward: 1, loss: 139.34893798828125\n",
      "g_step: 449, action: 0, reward: 1, loss: 34.25672149658203\n",
      "g_step: 450, action: 0, reward: 1, loss: 34.25675582885742\n",
      "g_step: 451, action: 0, reward: 1, loss: 29.172283172607422\n",
      "g_step: 452, action: 0, reward: 1, loss: 24.361536026000977\n",
      "g_step: 453, action: 0, reward: 1, loss: 18.824317932128906\n",
      "g_step: 454, action: 0, reward: 1, loss: 22.70322036743164\n",
      "g_step: 455, action: 0, reward: 1, loss: 18.09315299987793\n",
      "g_step: 456, action: 0, reward: 1, loss: 120.68911743164062\n",
      "g_step: 457, action: 0, reward: 1, loss: 19.707958221435547\n",
      "g_step: 458, action: 0, reward: 1, loss: 389.0909423828125\n",
      "g_step: 459, action: 0, reward: 1, loss: 387.3381042480469\n",
      "Episode 5, Total reward: 16, Total loss: 7869.477119445801, Epsilon: 0.009999505\n",
      "g_step: 460, action: 0, reward: 1, loss: 32.823143005371094\n",
      "g_step: 461, action: 0, reward: 1, loss: 24.852035522460938\n",
      "g_step: 462, action: 0, reward: 1, loss: 43.69820785522461\n",
      "g_step: 463, action: 0, reward: 1, loss: 21.54224395751953\n",
      "g_step: 464, action: 0, reward: 1, loss: 30.376527786254883\n",
      "g_step: 465, action: 0, reward: 1, loss: 56.659263610839844\n",
      "g_step: 466, action: 0, reward: 1, loss: 13.732118606567383\n",
      "g_step: 467, action: 0, reward: 1, loss: 17.076793670654297\n",
      "g_step: 468, action: 0, reward: 1, loss: 45.313575744628906\n",
      "g_step: 469, action: 0, reward: 1, loss: 23.70880889892578\n",
      "g_step: 470, action: 0, reward: 1, loss: 30.461078643798828\n",
      "g_step: 471, action: 0, reward: 1, loss: 45.6556282043457\n",
      "g_step: 472, action: 0, reward: 1, loss: 38.449851989746094\n",
      "g_step: 473, action: 0, reward: 1, loss: 18.34129524230957\n",
      "g_step: 474, action: 0, reward: 1, loss: 50.396236419677734\n",
      "g_step: 475, action: 0, reward: 1, loss: 26.411012649536133\n",
      "g_step: 476, action: 0, reward: 1, loss: 450.955322265625\n",
      "g_step: 477, action: 0, reward: 1, loss: 21.174808502197266\n",
      "g_step: 478, action: 0, reward: 1, loss: 393.0274353027344\n",
      "g_step: 479, action: 0, reward: 1, loss: 25.44937515258789\n",
      "g_step: 480, action: 0, reward: 1, loss: 19.480667114257812\n",
      "g_step: 481, action: 0, reward: 1, loss: 159.70164489746094\n",
      "g_step: 482, action: 0, reward: 1, loss: 103.30994415283203\n",
      "g_step: 483, action: 0, reward: 1, loss: 24.061752319335938\n",
      "g_step: 484, action: 0, reward: 1, loss: 41.12210464477539\n",
      "g_step: 485, action: 0, reward: 1, loss: 12.084684371948242\n",
      "g_step: 486, action: 0, reward: 1, loss: 19.995628356933594\n",
      "g_step: 487, action: 0, reward: 1, loss: 13.659319877624512\n",
      "g_step: 488, action: 0, reward: 1, loss: 13.21566390991211\n",
      "g_step: 489, action: 0, reward: 1, loss: 41.681427001953125\n",
      "g_step: 490, action: 0, reward: 1, loss: 35.55113983154297\n",
      "g_step: 491, action: 0, reward: 1, loss: 45.19224166870117\n",
      "g_step: 492, action: 0, reward: 1, loss: 81.12439727783203\n",
      "g_step: 493, action: 0, reward: 1, loss: 29.552778244018555\n",
      "g_step: 494, action: 0, reward: 1, loss: 28.704471588134766\n",
      "g_step: 495, action: 0, reward: 1, loss: 20.1005859375\n",
      "g_step: 496, action: 0, reward: 1, loss: 17.332271575927734\n",
      "g_step: 497, action: 0, reward: 1, loss: 8.64426040649414\n",
      "g_step: 498, action: 0, reward: 1, loss: 11.505130767822266\n",
      "g_step: 499, action: 0, reward: 1, loss: 313.6536560058594\n",
      "g_step: 500, action: 0, reward: 1, loss: 12.824748992919922\n",
      "g_step: 501, action: 0, reward: 1, loss: 73.37097930908203\n",
      "g_step: 502, action: 0, reward: 1, loss: 308.4431457519531\n",
      "g_step: 503, action: 0, reward: 1, loss: 9.03815746307373\n",
      "g_step: 504, action: 0, reward: 1, loss: 109.75907897949219\n",
      "g_step: 505, action: 0, reward: 1, loss: 49.68367385864258\n",
      "g_step: 506, action: 0, reward: 1, loss: 118.1953125\n",
      "g_step: 507, action: 0, reward: 1, loss: 28.884994506835938\n",
      "g_step: 508, action: 0, reward: 1, loss: 15.949994087219238\n",
      "g_step: 509, action: 0, reward: 1, loss: 13.342702865600586\n",
      "g_step: 510, action: 0, reward: 1, loss: 19.643423080444336\n",
      "g_step: 511, action: 0, reward: 1, loss: 156.25051879882812\n",
      "g_step: 512, action: 0, reward: 1, loss: 94.56649017333984\n",
      "g_step: 513, action: 0, reward: 1, loss: 16.362895965576172\n",
      "g_step: 514, action: 0, reward: 1, loss: 13.739959716796875\n",
      "g_step: 515, action: 0, reward: 1, loss: 263.6546325683594\n",
      "g_step: 516, action: 0, reward: 1, loss: 77.81596374511719\n",
      "g_step: 517, action: 0, reward: 1, loss: 20.62603187561035\n",
      "Episode 6, Total reward: 58, Total loss: 3851.931237220764, Epsilon: 0.009999406\n",
      "g_step: 518, action: 0, reward: 1, loss: 67.97919464111328\n",
      "g_step: 519, action: 0, reward: 1, loss: 18.534374237060547\n",
      "g_step: 520, action: 0, reward: 1, loss: 35.249046325683594\n",
      "g_step: 521, action: 0, reward: 1, loss: 20.21767234802246\n",
      "g_step: 522, action: 0, reward: 1, loss: 230.2977752685547\n",
      "g_step: 523, action: 0, reward: 1, loss: 40.86844253540039\n",
      "g_step: 524, action: 0, reward: 1, loss: 35.086814880371094\n",
      "g_step: 525, action: 0, reward: 1, loss: 22.279808044433594\n",
      "g_step: 526, action: 0, reward: 1, loss: 22.285614013671875\n",
      "g_step: 527, action: 0, reward: 1, loss: 17.106304168701172\n",
      "g_step: 528, action: 0, reward: 1, loss: 74.55625915527344\n",
      "g_step: 529, action: 0, reward: 1, loss: 17.52840805053711\n",
      "g_step: 530, action: 0, reward: 1, loss: 16.880979537963867\n",
      "g_step: 531, action: 0, reward: 1, loss: 53.53633499145508\n",
      "g_step: 532, action: 0, reward: 1, loss: 25.63645362854004\n",
      "g_step: 533, action: 0, reward: 1, loss: 62.4006462097168\n",
      "g_step: 534, action: 0, reward: 1, loss: 38.747703552246094\n",
      "g_step: 535, action: 0, reward: 1, loss: 42.484588623046875\n",
      "g_step: 536, action: 0, reward: 1, loss: 65.5052261352539\n",
      "g_step: 537, action: 0, reward: 1, loss: 13.38473129272461\n",
      "g_step: 538, action: 0, reward: 1, loss: 26.758159637451172\n",
      "g_step: 539, action: 0, reward: 1, loss: 16.742403030395508\n",
      "g_step: 540, action: 0, reward: 1, loss: 20.18431282043457\n",
      "g_step: 541, action: 0, reward: 1, loss: 30.99779510498047\n",
      "g_step: 542, action: 0, reward: 1, loss: 59.01723098754883\n",
      "g_step: 543, action: 0, reward: 1, loss: 15.266722679138184\n",
      "g_step: 544, action: 0, reward: 1, loss: 40.618534088134766\n",
      "g_step: 545, action: 0, reward: 1, loss: 29.276031494140625\n",
      "g_step: 546, action: 0, reward: 1, loss: 16.348388671875\n",
      "g_step: 547, action: 0, reward: 1, loss: 39.22319412231445\n",
      "g_step: 548, action: 0, reward: 1, loss: 44.224971771240234\n",
      "g_step: 549, action: 0, reward: 1, loss: 19.232833862304688\n",
      "g_step: 550, action: 0, reward: 1, loss: 23.91115951538086\n",
      "g_step: 551, action: 0, reward: 1, loss: 13.389144897460938\n",
      "g_step: 552, action: 0, reward: 1, loss: 354.5915832519531\n",
      "g_step: 553, action: 0, reward: 1, loss: 41.94091796875\n",
      "g_step: 554, action: 0, reward: 1, loss: 27.48078727722168\n",
      "g_step: 555, action: 0, reward: 1, loss: 59.28534698486328\n",
      "g_step: 556, action: 0, reward: 1, loss: 27.195266723632812\n",
      "g_step: 557, action: 0, reward: 1, loss: 15.989484786987305\n",
      "g_step: 558, action: 0, reward: 1, loss: 36.42298889160156\n",
      "g_step: 559, action: 0, reward: 1, loss: 20.376047134399414\n",
      "g_step: 560, action: 0, reward: 1, loss: 31.687936782836914\n",
      "g_step: 561, action: 0, reward: 1, loss: 30.37910270690918\n",
      "g_step: 562, action: 0, reward: 1, loss: 41.59647750854492\n",
      "g_step: 563, action: 0, reward: 1, loss: 15.361318588256836\n",
      "g_step: 564, action: 0, reward: 1, loss: 21.728675842285156\n",
      "g_step: 565, action: 0, reward: 1, loss: 76.73949432373047\n",
      "g_step: 566, action: 0, reward: 1, loss: 67.48828887939453\n",
      "g_step: 567, action: 0, reward: 1, loss: 25.623432159423828\n",
      "g_step: 568, action: 0, reward: 1, loss: 25.806529998779297\n",
      "g_step: 569, action: 0, reward: 1, loss: 27.6276798248291\n",
      "g_step: 570, action: 0, reward: 1, loss: 25.205827713012695\n",
      "g_step: 571, action: 0, reward: 1, loss: 36.66654968261719\n",
      "g_step: 572, action: 0, reward: 1, loss: 15.55283260345459\n",
      "g_step: 573, action: 0, reward: 1, loss: 16.07476043701172\n",
      "g_step: 574, action: 0, reward: 1, loss: 51.91448974609375\n",
      "g_step: 575, action: 0, reward: 1, loss: 52.52246856689453\n",
      "g_step: 576, action: 0, reward: 1, loss: 30.210491180419922\n",
      "Episode 7, Total reward: 59, Total loss: 2491.2260398864746, Epsilon: 0.009999307\n",
      "g_step: 577, action: 0, reward: 1, loss: 24.754547119140625\n",
      "g_step: 578, action: 0, reward: 1, loss: 30.449119567871094\n",
      "g_step: 579, action: 0, reward: 1, loss: 21.22088623046875\n",
      "g_step: 580, action: 0, reward: 1, loss: 28.69468116760254\n",
      "g_step: 581, action: 0, reward: 1, loss: 16.566024780273438\n",
      "g_step: 582, action: 0, reward: 1, loss: 303.5920104980469\n",
      "g_step: 583, action: 0, reward: 1, loss: 14.226696014404297\n",
      "g_step: 584, action: 0, reward: 1, loss: 23.492658615112305\n",
      "g_step: 585, action: 0, reward: 1, loss: 64.2247543334961\n",
      "g_step: 586, action: 0, reward: 1, loss: 21.371810913085938\n",
      "g_step: 587, action: 0, reward: 1, loss: 23.87906265258789\n",
      "g_step: 588, action: 0, reward: 1, loss: 17.41538429260254\n",
      "g_step: 589, action: 0, reward: 1, loss: 19.49380111694336\n",
      "g_step: 590, action: 0, reward: 1, loss: 22.453550338745117\n",
      "g_step: 591, action: 0, reward: 1, loss: 18.757949829101562\n",
      "g_step: 592, action: 0, reward: 1, loss: 38.41451644897461\n",
      "g_step: 593, action: 0, reward: 1, loss: 45.755638122558594\n",
      "g_step: 594, action: 0, reward: 1, loss: 20.127464294433594\n",
      "g_step: 595, action: 0, reward: 1, loss: 49.044281005859375\n",
      "g_step: 596, action: 0, reward: 1, loss: 18.235830307006836\n",
      "g_step: 597, action: 0, reward: 1, loss: 9.532363891601562\n",
      "g_step: 598, action: 0, reward: 1, loss: 46.84309387207031\n",
      "g_step: 599, action: 0, reward: 1, loss: 81.3756103515625\n",
      "g_step: 600, action: 0, reward: 1, loss: 19.31325912475586\n",
      "g_step: 601, action: 0, reward: 1, loss: 17.911090850830078\n",
      "g_step: 602, action: 0, reward: 1, loss: 54.97725296020508\n",
      "g_step: 603, action: 0, reward: 1, loss: 50.91227722167969\n",
      "g_step: 604, action: 0, reward: 1, loss: 18.868215560913086\n",
      "g_step: 605, action: 0, reward: 1, loss: 45.477272033691406\n",
      "g_step: 606, action: 0, reward: 1, loss: 12.294724464416504\n",
      "g_step: 607, action: 0, reward: 1, loss: 39.396400451660156\n",
      "g_step: 608, action: 0, reward: 1, loss: 28.46261978149414\n",
      "g_step: 609, action: 0, reward: 1, loss: 44.609535217285156\n",
      "g_step: 610, action: 0, reward: 1, loss: 17.14078140258789\n",
      "g_step: 611, action: 0, reward: 1, loss: 19.427480697631836\n",
      "g_step: 612, action: 0, reward: 1, loss: 39.0883903503418\n",
      "g_step: 613, action: 0, reward: 1, loss: 40.52374267578125\n",
      "g_step: 614, action: 0, reward: 1, loss: 10.52983570098877\n",
      "g_step: 615, action: 0, reward: 1, loss: 39.487300872802734\n",
      "g_step: 616, action: 0, reward: 1, loss: 16.43151092529297\n",
      "g_step: 617, action: 0, reward: 1, loss: 11.887968063354492\n",
      "g_step: 618, action: 0, reward: 1, loss: 71.48179626464844\n",
      "g_step: 619, action: 0, reward: 1, loss: 17.72648048400879\n",
      "g_step: 620, action: 0, reward: 1, loss: 23.16991424560547\n",
      "g_step: 621, action: 0, reward: 1, loss: 14.078302383422852\n",
      "g_step: 622, action: 0, reward: 1, loss: 35.22900390625\n",
      "g_step: 623, action: 0, reward: 1, loss: 339.8114013671875\n",
      "g_step: 624, action: 0, reward: 1, loss: 10.114795684814453\n",
      "g_step: 625, action: 0, reward: 1, loss: 21.511302947998047\n",
      "g_step: 626, action: 0, reward: 1, loss: 306.66021728515625\n",
      "g_step: 627, action: 0, reward: 1, loss: 18.74017333984375\n",
      "g_step: 628, action: 0, reward: 1, loss: 26.07624053955078\n",
      "g_step: 629, action: 0, reward: 1, loss: 31.2838077545166\n",
      "g_step: 630, action: 0, reward: 1, loss: 25.816333770751953\n",
      "g_step: 631, action: 0, reward: 1, loss: 24.958301544189453\n",
      "g_step: 632, action: 0, reward: 1, loss: 22.899978637695312\n",
      "g_step: 633, action: 0, reward: 1, loss: 25.291017532348633\n",
      "g_step: 634, action: 0, reward: 1, loss: 17.53519058227539\n",
      "g_step: 635, action: 0, reward: 1, loss: 12.168851852416992\n",
      "Episode 8, Total reward: 59, Total loss: 2531.2145042419434, Epsilon: 0.009999208\n",
      "g_step: 636, action: 0, reward: 1, loss: 67.0671157836914\n",
      "g_step: 637, action: 0, reward: 1, loss: 26.999683380126953\n",
      "g_step: 638, action: 0, reward: 1, loss: 13.885416030883789\n",
      "g_step: 639, action: 0, reward: 1, loss: 23.644638061523438\n",
      "g_step: 640, action: 0, reward: 1, loss: 19.55514907836914\n",
      "g_step: 641, action: 0, reward: 1, loss: 24.099262237548828\n",
      "g_step: 642, action: 0, reward: 1, loss: 39.518699645996094\n",
      "g_step: 643, action: 0, reward: 1, loss: 36.0179557800293\n",
      "g_step: 644, action: 1, reward: -3, loss: 17.60034942626953\n",
      "g_step: 645, action: 0, reward: 1, loss: 17.76715087890625\n",
      "g_step: 646, action: 0, reward: 1, loss: 39.57401657104492\n",
      "g_step: 647, action: 0, reward: 1, loss: 25.92264175415039\n",
      "g_step: 648, action: 0, reward: 1, loss: 13.664409637451172\n",
      "g_step: 649, action: 0, reward: 1, loss: 20.148334503173828\n",
      "g_step: 650, action: 0, reward: 1, loss: 46.352783203125\n",
      "g_step: 651, action: 0, reward: 1, loss: 24.975961685180664\n",
      "g_step: 652, action: 0, reward: 1, loss: 27.591276168823242\n",
      "g_step: 653, action: 0, reward: 1, loss: 28.558794021606445\n",
      "g_step: 654, action: 0, reward: 1, loss: 16.45604705810547\n",
      "g_step: 655, action: 0, reward: 1, loss: 21.725215911865234\n",
      "g_step: 656, action: 0, reward: 1, loss: 33.53033447265625\n",
      "g_step: 657, action: 0, reward: 1, loss: 26.381866455078125\n",
      "g_step: 658, action: 0, reward: 1, loss: 17.800655364990234\n",
      "g_step: 659, action: 0, reward: 1, loss: 14.192197799682617\n",
      "g_step: 660, action: 0, reward: 1, loss: 8.926713943481445\n",
      "g_step: 661, action: 0, reward: 1, loss: 20.60425567626953\n",
      "g_step: 662, action: 0, reward: 1, loss: 14.821914672851562\n",
      "g_step: 663, action: 0, reward: 1, loss: 15.913091659545898\n",
      "g_step: 664, action: 0, reward: 1, loss: 21.669986724853516\n",
      "g_step: 665, action: 0, reward: 1, loss: 261.8181457519531\n",
      "g_step: 666, action: 0, reward: 1, loss: 18.00899887084961\n",
      "g_step: 667, action: 0, reward: 1, loss: 10.95235538482666\n",
      "g_step: 668, action: 0, reward: 1, loss: 15.160888671875\n",
      "g_step: 669, action: 1, reward: -3, loss: 62.94361877441406\n",
      "g_step: 670, action: 0, reward: 1, loss: 21.448394775390625\n",
      "g_step: 671, action: 0, reward: 1, loss: 42.903846740722656\n",
      "g_step: 672, action: 0, reward: 1, loss: 18.175535202026367\n",
      "g_step: 673, action: 0, reward: 1, loss: 18.49542808532715\n",
      "g_step: 674, action: 0, reward: 1, loss: 17.470102310180664\n",
      "g_step: 675, action: 0, reward: 1, loss: 7.982759475708008\n",
      "g_step: 676, action: 0, reward: 1, loss: 13.164947509765625\n",
      "g_step: 677, action: 0, reward: 1, loss: 18.592456817626953\n",
      "g_step: 678, action: 0, reward: 1, loss: 12.393054962158203\n",
      "g_step: 679, action: 0, reward: 1, loss: 30.171236038208008\n",
      "g_step: 680, action: 0, reward: 1, loss: 22.07347869873047\n",
      "g_step: 681, action: 0, reward: 1, loss: 10.377687454223633\n",
      "g_step: 682, action: 0, reward: 1, loss: 13.824708938598633\n",
      "g_step: 683, action: 0, reward: 1, loss: 14.746803283691406\n",
      "g_step: 684, action: 0, reward: 1, loss: 15.067276000976562\n",
      "g_step: 685, action: 0, reward: 1, loss: 12.338485717773438\n",
      "g_step: 686, action: 0, reward: 1, loss: 26.641706466674805\n",
      "g_step: 687, action: 0, reward: 1, loss: 11.281196594238281\n",
      "g_step: 688, action: 0, reward: 1, loss: 14.688234329223633\n",
      "g_step: 689, action: 0, reward: 1, loss: 11.123140335083008\n",
      "g_step: 690, action: 0, reward: 1, loss: 38.975650787353516\n",
      "g_step: 691, action: 0, reward: 1, loss: 18.154388427734375\n",
      "g_step: 692, action: 0, reward: 1, loss: 25.033309936523438\n",
      "g_step: 693, action: 0, reward: 1, loss: 19.58350944519043\n",
      "Episode 9, Total reward: 50, Total loss: 1548.5572633743286, Epsilon: 0.009999109\n",
      "g_step: 694, action: 0, reward: 1, loss: 26.323074340820312\n",
      "g_step: 695, action: 0, reward: 1, loss: 17.515954971313477\n",
      "g_step: 696, action: 0, reward: 1, loss: 12.702085494995117\n",
      "g_step: 697, action: 0, reward: 1, loss: 23.80498695373535\n",
      "g_step: 698, action: 0, reward: 1, loss: 14.092510223388672\n",
      "g_step: 699, action: 0, reward: 1, loss: 11.245206832885742\n",
      "g_step: 700, action: 0, reward: 1, loss: 11.264735221862793\n",
      "g_step: 701, action: 0, reward: 1, loss: 9.417146682739258\n",
      "g_step: 702, action: 0, reward: 1, loss: 14.83993911743164\n",
      "g_step: 703, action: 0, reward: 1, loss: 20.859363555908203\n",
      "g_step: 704, action: 0, reward: 1, loss: 17.536941528320312\n",
      "g_step: 705, action: 0, reward: 1, loss: 37.744022369384766\n",
      "g_step: 706, action: 0, reward: 1, loss: 19.073192596435547\n",
      "g_step: 707, action: 0, reward: 1, loss: 12.64813232421875\n",
      "g_step: 708, action: 0, reward: 1, loss: 12.739264488220215\n",
      "g_step: 709, action: 0, reward: 1, loss: 16.640880584716797\n",
      "g_step: 710, action: 0, reward: 1, loss: 16.49373435974121\n",
      "g_step: 711, action: 0, reward: 1, loss: 6.881651878356934\n",
      "g_step: 712, action: 0, reward: 1, loss: 9.512526512145996\n",
      "g_step: 713, action: 0, reward: 1, loss: 11.434310913085938\n",
      "g_step: 714, action: 0, reward: 1, loss: 11.935808181762695\n",
      "g_step: 715, action: 0, reward: 1, loss: 11.244104385375977\n",
      "g_step: 716, action: 0, reward: 1, loss: 12.936498641967773\n",
      "g_step: 717, action: 0, reward: 1, loss: 282.35772705078125\n",
      "g_step: 718, action: 0, reward: 1, loss: 35.9869499206543\n",
      "g_step: 719, action: 0, reward: 1, loss: 12.264795303344727\n",
      "g_step: 720, action: 0, reward: 1, loss: 12.05419921875\n",
      "g_step: 721, action: 0, reward: 1, loss: 8.235359191894531\n",
      "g_step: 722, action: 0, reward: 1, loss: 8.56772232055664\n",
      "g_step: 723, action: 0, reward: 1, loss: 20.318649291992188\n",
      "g_step: 724, action: 0, reward: 1, loss: 15.723203659057617\n",
      "g_step: 725, action: 0, reward: 1, loss: 11.342979431152344\n",
      "g_step: 726, action: 0, reward: 1, loss: 10.600988388061523\n",
      "g_step: 727, action: 0, reward: 1, loss: 12.909082412719727\n",
      "g_step: 728, action: 0, reward: 1, loss: 8.814430236816406\n",
      "g_step: 729, action: 0, reward: 1, loss: 8.55583381652832\n",
      "g_step: 730, action: 0, reward: 1, loss: 23.418807983398438\n",
      "g_step: 731, action: 0, reward: 1, loss: 9.410388946533203\n",
      "g_step: 732, action: 0, reward: 1, loss: 17.344402313232422\n",
      "g_step: 733, action: 0, reward: 1, loss: 15.920780181884766\n",
      "g_step: 734, action: 0, reward: 1, loss: 11.308862686157227\n",
      "g_step: 735, action: 0, reward: 1, loss: 12.552626609802246\n",
      "g_step: 736, action: 0, reward: 1, loss: 5.287798881530762\n",
      "g_step: 737, action: 0, reward: 1, loss: 19.513105392456055\n",
      "g_step: 738, action: 0, reward: 1, loss: 28.73178482055664\n",
      "g_step: 739, action: 0, reward: 1, loss: 15.233112335205078\n",
      "g_step: 740, action: 0, reward: 1, loss: 13.082961082458496\n",
      "g_step: 741, action: 0, reward: 1, loss: 13.061782836914062\n",
      "g_step: 742, action: 0, reward: 1, loss: 14.512481689453125\n",
      "g_step: 743, action: 0, reward: 1, loss: 6.304836273193359\n",
      "g_step: 744, action: 0, reward: 1, loss: 13.19342041015625\n",
      "g_step: 745, action: 0, reward: 1, loss: 15.533317565917969\n",
      "g_step: 746, action: 0, reward: 1, loss: 13.547883987426758\n",
      "g_step: 747, action: 0, reward: 1, loss: 10.825420379638672\n",
      "g_step: 748, action: 0, reward: 1, loss: 230.24851989746094\n",
      "g_step: 749, action: 0, reward: 1, loss: 10.752696990966797\n",
      "g_step: 750, action: 0, reward: 1, loss: 23.412261962890625\n",
      "g_step: 751, action: 0, reward: 1, loss: 6.983887195587158\n",
      "g_step: 752, action: 0, reward: 1, loss: 18.711956024169922\n",
      "Episode 10, Total reward: 59, Total loss: 1355.511088848114, Epsilon: 0.009999010000000001\n",
      "g_step: 753, action: 0, reward: 1, loss: 9.824089050292969\n",
      "g_step: 754, action: 0, reward: 1, loss: 30.60623550415039\n",
      "g_step: 755, action: 0, reward: 1, loss: 10.680052757263184\n",
      "g_step: 756, action: 0, reward: 1, loss: 7.247737884521484\n",
      "g_step: 757, action: 0, reward: 1, loss: 22.704824447631836\n",
      "g_step: 758, action: 0, reward: 1, loss: 10.76447868347168\n",
      "g_step: 759, action: 0, reward: 1, loss: 8.82597827911377\n",
      "g_step: 760, action: 0, reward: 1, loss: 11.824605941772461\n",
      "g_step: 761, action: 0, reward: 1, loss: 13.218377113342285\n",
      "g_step: 762, action: 0, reward: 1, loss: 156.64320373535156\n",
      "g_step: 763, action: 0, reward: 1, loss: 20.048595428466797\n",
      "g_step: 764, action: 0, reward: 1, loss: 15.719989776611328\n",
      "g_step: 765, action: 0, reward: 1, loss: 9.422356605529785\n",
      "g_step: 766, action: 0, reward: 1, loss: 30.130510330200195\n",
      "g_step: 767, action: 0, reward: 1, loss: 10.918859481811523\n",
      "g_step: 768, action: 0, reward: 1, loss: 8.639104843139648\n",
      "g_step: 769, action: 0, reward: 1, loss: 11.863988876342773\n",
      "g_step: 770, action: 0, reward: 1, loss: 15.891977310180664\n",
      "g_step: 771, action: 0, reward: 1, loss: 12.751943588256836\n",
      "g_step: 772, action: 0, reward: 1, loss: 21.171924591064453\n",
      "g_step: 773, action: 0, reward: 1, loss: 12.75439453125\n",
      "g_step: 774, action: 0, reward: 1, loss: 8.978859901428223\n",
      "g_step: 775, action: 0, reward: 1, loss: 17.34640884399414\n",
      "g_step: 776, action: 0, reward: 1, loss: 11.096487045288086\n",
      "g_step: 777, action: 0, reward: 1, loss: 10.091564178466797\n",
      "g_step: 778, action: 0, reward: 1, loss: 13.978944778442383\n",
      "g_step: 779, action: 0, reward: 1, loss: 29.04055404663086\n",
      "g_step: 780, action: 0, reward: 1, loss: 8.661850929260254\n",
      "g_step: 781, action: 0, reward: 1, loss: 9.688375473022461\n",
      "g_step: 782, action: 0, reward: 1, loss: 165.75152587890625\n",
      "g_step: 783, action: 0, reward: 1, loss: 22.594318389892578\n",
      "g_step: 784, action: 0, reward: 1, loss: 15.330072402954102\n",
      "g_step: 785, action: 0, reward: 1, loss: 16.733352661132812\n",
      "g_step: 786, action: 0, reward: 1, loss: 7.108393669128418\n",
      "g_step: 787, action: 0, reward: 1, loss: 17.511268615722656\n",
      "g_step: 788, action: 0, reward: 1, loss: 7.373183250427246\n",
      "g_step: 789, action: 0, reward: 1, loss: 5.4373040199279785\n",
      "g_step: 790, action: 0, reward: 1, loss: 17.99346351623535\n",
      "g_step: 791, action: 0, reward: 1, loss: 119.12150573730469\n",
      "g_step: 792, action: 0, reward: 1, loss: 5.656671524047852\n",
      "g_step: 793, action: 0, reward: 1, loss: 7.462536811828613\n",
      "g_step: 794, action: 0, reward: 1, loss: 12.685102462768555\n",
      "g_step: 795, action: 0, reward: 1, loss: 16.128259658813477\n",
      "g_step: 796, action: 0, reward: 1, loss: 26.789262771606445\n",
      "g_step: 797, action: 0, reward: 1, loss: 29.686786651611328\n",
      "g_step: 798, action: 0, reward: 1, loss: 92.83737182617188\n",
      "g_step: 799, action: 0, reward: 1, loss: 24.95661163330078\n",
      "g_step: 800, action: 0, reward: 1, loss: 16.167430877685547\n",
      "g_step: 801, action: 0, reward: 1, loss: 13.206120491027832\n",
      "g_step: 802, action: 0, reward: 1, loss: 22.1298828125\n",
      "g_step: 803, action: 0, reward: 1, loss: 23.094894409179688\n",
      "g_step: 804, action: 0, reward: 1, loss: 21.400897979736328\n",
      "g_step: 805, action: 0, reward: 1, loss: 15.170642852783203\n",
      "g_step: 806, action: 0, reward: 1, loss: 19.117321014404297\n",
      "g_step: 807, action: 0, reward: 1, loss: 8.300968170166016\n",
      "g_step: 808, action: 0, reward: 1, loss: 23.2841739654541\n",
      "g_step: 809, action: 0, reward: 1, loss: 14.883572578430176\n",
      "g_step: 810, action: 0, reward: 1, loss: 31.38871192932129\n",
      "g_step: 811, action: 0, reward: -100, loss: 19.870893478393555\n",
      "g_step: 812, action: 0, reward: 1, loss: 998.6666259765625\n",
      "g_step: 813, action: 0, reward: 1, loss: 12.310127258300781\n",
      "g_step: 814, action: 0, reward: 1, loss: 14.039758682250977\n",
      "g_step: 815, action: 0, reward: 1, loss: 13.206136703491211\n",
      "g_step: 816, action: 0, reward: 1, loss: 13.45235824584961\n",
      "g_step: 817, action: 0, reward: 1, loss: 22.467065811157227\n",
      "g_step: 818, action: 0, reward: 1, loss: 13.047685623168945\n",
      "g_step: 819, action: 0, reward: 1, loss: 25.615985870361328\n",
      "g_step: 820, action: 0, reward: 1, loss: 18.04409408569336\n",
      "g_step: 821, action: 0, reward: 1, loss: 11.11644458770752\n",
      "g_step: 822, action: 0, reward: 1, loss: 19.70183753967285\n",
      "g_step: 823, action: 0, reward: 1, loss: 31.06814956665039\n",
      "g_step: 824, action: 0, reward: 1, loss: 16.855388641357422\n",
      "g_step: 825, action: 0, reward: 1, loss: 484.5451965332031\n",
      "g_step: 826, action: 0, reward: 1, loss: 16.242788314819336\n",
      "g_step: 827, action: 0, reward: 1, loss: 19.522659301757812\n",
      "g_step: 828, action: 0, reward: 1, loss: 23.034345626831055\n",
      "g_step: 829, action: 0, reward: 1, loss: 9.908384323120117\n",
      "g_step: 830, action: 0, reward: 1, loss: 18.88617515563965\n",
      "g_step: 831, action: 0, reward: 1, loss: 20.94357681274414\n",
      "g_step: 832, action: 0, reward: 1, loss: 24.01197052001953\n",
      "g_step: 833, action: 0, reward: 1, loss: 22.656665802001953\n",
      "g_step: 834, action: 0, reward: 1, loss: 18.229713439941406\n",
      "g_step: 835, action: 0, reward: 1, loss: 38.68238067626953\n",
      "g_step: 836, action: 0, reward: 1, loss: 15.460631370544434\n",
      "g_step: 837, action: 0, reward: 1, loss: 12.303413391113281\n",
      "g_step: 838, action: 0, reward: 1, loss: 23.60626983642578\n",
      "g_step: 839, action: 0, reward: 1, loss: 85.02420043945312\n",
      "g_step: 840, action: 0, reward: 1, loss: 25.49443244934082\n",
      "g_step: 841, action: 0, reward: 1, loss: 35.280941009521484\n",
      "g_step: 842, action: 0, reward: 1, loss: 323.5029296875\n",
      "g_step: 843, action: 0, reward: 1, loss: 8.744223594665527\n",
      "g_step: 844, action: 0, reward: 1, loss: 11.311765670776367\n",
      "g_step: 845, action: 0, reward: 1, loss: 23.315479278564453\n",
      "g_step: 846, action: 0, reward: 1, loss: 23.535602569580078\n",
      "g_step: 847, action: 0, reward: 1, loss: 16.000314712524414\n",
      "g_step: 848, action: 0, reward: 1, loss: 38.200626373291016\n",
      "g_step: 849, action: 0, reward: 1, loss: 10.558358192443848\n",
      "g_step: 850, action: 0, reward: 1, loss: 246.29193115234375\n",
      "g_step: 851, action: 0, reward: 1, loss: 11.468348503112793\n",
      "g_step: 852, action: 0, reward: 1, loss: 122.70315551757812\n",
      "g_step: 853, action: 0, reward: 1, loss: 24.38995361328125\n",
      "g_step: 854, action: 0, reward: 1, loss: 75.63925170898438\n",
      "g_step: 855, action: 0, reward: 1, loss: 33.91053771972656\n",
      "g_step: 856, action: 0, reward: 1, loss: 13.708961486816406\n",
      "g_step: 857, action: 0, reward: 1, loss: 12.049253463745117\n",
      "g_step: 858, action: 0, reward: 1, loss: 18.886093139648438\n",
      "g_step: 859, action: 0, reward: 1, loss: 33.38725280761719\n",
      "g_step: 860, action: 0, reward: 1, loss: 18.015811920166016\n",
      "g_step: 861, action: 0, reward: 1, loss: 18.002086639404297\n",
      "g_step: 862, action: 0, reward: 1, loss: 40.171958923339844\n",
      "g_step: 863, action: 0, reward: 1, loss: 14.568853378295898\n",
      "g_step: 864, action: 0, reward: 1, loss: 46.10615921020508\n",
      "g_step: 865, action: 0, reward: 1, loss: 26.421842575073242\n",
      "g_step: 866, action: 0, reward: 1, loss: 16.766159057617188\n",
      "g_step: 867, action: 0, reward: 1, loss: 15.029796600341797\n",
      "g_step: 868, action: 1, reward: -3, loss: 30.956523895263672\n",
      "g_step: 869, action: 0, reward: 1, loss: 11.002668380737305\n",
      "g_step: 870, action: 0, reward: 1, loss: 29.994380950927734\n",
      "g_step: 871, action: 0, reward: 1, loss: 18.633852005004883\n",
      "g_step: 872, action: 0, reward: 1, loss: 266.54571533203125\n",
      "g_step: 873, action: 0, reward: 1, loss: 236.09640502929688\n",
      "g_step: 874, action: 0, reward: 1, loss: 13.309553146362305\n",
      "g_step: 875, action: 0, reward: 1, loss: 25.25847625732422\n",
      "g_step: 876, action: 0, reward: 1, loss: 23.702306747436523\n",
      "g_step: 877, action: 0, reward: 1, loss: 130.9461212158203\n",
      "g_step: 878, action: 0, reward: 1, loss: 42.005470275878906\n",
      "g_step: 879, action: 0, reward: 1, loss: 30.12295913696289\n",
      "Episode 11, Total reward: 22, Total loss: 5604.3953194618225, Epsilon: 0.009998911000000001\n",
      "g_step: 880, action: 0, reward: 1, loss: 75.97673034667969\n",
      "g_step: 881, action: 0, reward: 1, loss: 23.749862670898438\n",
      "g_step: 882, action: 0, reward: 1, loss: 8.484210014343262\n",
      "g_step: 883, action: 0, reward: 1, loss: 18.693227767944336\n",
      "g_step: 884, action: 0, reward: 1, loss: 16.041427612304688\n",
      "g_step: 885, action: 0, reward: 1, loss: 14.152189254760742\n",
      "g_step: 886, action: 0, reward: 1, loss: 18.57297134399414\n",
      "g_step: 887, action: 0, reward: 1, loss: 11.627042770385742\n",
      "g_step: 888, action: 0, reward: 1, loss: 16.845590591430664\n",
      "g_step: 889, action: 0, reward: 1, loss: 38.34479904174805\n",
      "g_step: 890, action: 0, reward: 1, loss: 17.35548973083496\n",
      "g_step: 891, action: 0, reward: 1, loss: 24.561641693115234\n",
      "g_step: 892, action: 0, reward: 1, loss: 26.995563507080078\n",
      "g_step: 893, action: 0, reward: 1, loss: 57.02550506591797\n",
      "g_step: 894, action: 0, reward: 1, loss: 21.496673583984375\n",
      "g_step: 895, action: 0, reward: 1, loss: 80.07177734375\n",
      "g_step: 896, action: 0, reward: 1, loss: 30.42456817626953\n",
      "g_step: 897, action: 0, reward: 1, loss: 20.969562530517578\n",
      "g_step: 898, action: 0, reward: 1, loss: 31.03142547607422\n",
      "g_step: 899, action: 0, reward: 1, loss: 112.42523193359375\n",
      "g_step: 900, action: 0, reward: 1, loss: 10.328913688659668\n",
      "g_step: 901, action: 0, reward: 1, loss: 40.167808532714844\n",
      "g_step: 902, action: 0, reward: 1, loss: 13.478196144104004\n",
      "g_step: 903, action: 0, reward: 1, loss: 17.710556030273438\n",
      "g_step: 904, action: 0, reward: 1, loss: 17.264053344726562\n",
      "g_step: 905, action: 0, reward: 1, loss: 10.299686431884766\n",
      "g_step: 906, action: 0, reward: 1, loss: 12.728113174438477\n",
      "g_step: 907, action: 0, reward: 1, loss: 39.338134765625\n",
      "g_step: 908, action: 0, reward: 1, loss: 89.66234588623047\n",
      "g_step: 909, action: 0, reward: 1, loss: 35.9575080871582\n",
      "g_step: 910, action: 0, reward: 1, loss: 72.22653198242188\n",
      "g_step: 911, action: 0, reward: 1, loss: 24.32549285888672\n",
      "g_step: 912, action: 0, reward: 1, loss: 31.854816436767578\n",
      "g_step: 913, action: 0, reward: 1, loss: 23.356538772583008\n",
      "g_step: 914, action: 0, reward: 1, loss: 34.4032096862793\n",
      "g_step: 915, action: 0, reward: 1, loss: 18.96858024597168\n",
      "g_step: 916, action: 0, reward: 1, loss: 20.807636260986328\n",
      "g_step: 917, action: 0, reward: 1, loss: 21.245328903198242\n",
      "g_step: 918, action: 0, reward: 1, loss: 39.15593719482422\n",
      "g_step: 919, action: 0, reward: 1, loss: 7.731517791748047\n",
      "g_step: 920, action: 0, reward: 1, loss: 13.926542282104492\n",
      "g_step: 921, action: 0, reward: 1, loss: 74.61872100830078\n",
      "g_step: 922, action: 0, reward: 1, loss: 8.830321311950684\n",
      "g_step: 923, action: 0, reward: 1, loss: 48.38059997558594\n",
      "g_step: 924, action: 0, reward: 1, loss: 21.178255081176758\n",
      "g_step: 925, action: 0, reward: 1, loss: 17.93280601501465\n",
      "g_step: 926, action: 0, reward: 1, loss: 29.986854553222656\n",
      "g_step: 927, action: 0, reward: 1, loss: 43.51426315307617\n",
      "g_step: 928, action: 0, reward: 1, loss: 15.87607192993164\n",
      "g_step: 929, action: 0, reward: 1, loss: 18.23781967163086\n",
      "g_step: 930, action: 0, reward: 1, loss: 30.5687255859375\n",
      "g_step: 931, action: 0, reward: 1, loss: 15.364230155944824\n",
      "g_step: 932, action: 0, reward: 1, loss: 23.50992202758789\n",
      "g_step: 933, action: 0, reward: 1, loss: 11.432817459106445\n",
      "g_step: 934, action: 0, reward: 1, loss: 23.25429916381836\n",
      "g_step: 935, action: 0, reward: 1, loss: 76.32911682128906\n",
      "g_step: 936, action: 0, reward: 1, loss: 16.49830436706543\n",
      "g_step: 937, action: 0, reward: -100, loss: 66.63778686523438\n",
      "g_step: 938, action: 0, reward: 1, loss: 34.83271408081055\n",
      "g_step: 939, action: 0, reward: 1, loss: 12.779045104980469\n",
      "g_step: 940, action: 0, reward: 1, loss: 20.60224151611328\n",
      "g_step: 941, action: 0, reward: 1, loss: 16.02315902709961\n",
      "g_step: 942, action: 0, reward: 1, loss: 30.681396484375\n",
      "g_step: 943, action: 0, reward: 1, loss: 10.750441551208496\n",
      "g_step: 944, action: 0, reward: 1, loss: 25.798526763916016\n",
      "g_step: 945, action: 0, reward: 1, loss: 16.278703689575195\n",
      "g_step: 946, action: 0, reward: 1, loss: 20.014240264892578\n",
      "g_step: 947, action: 0, reward: 1, loss: 28.860210418701172\n",
      "g_step: 948, action: 0, reward: 1, loss: 47.78181838989258\n",
      "g_step: 949, action: 0, reward: 1, loss: 17.480236053466797\n",
      "g_step: 950, action: 0, reward: 1, loss: 16.489492416381836\n",
      "g_step: 951, action: 0, reward: 1, loss: 24.856103897094727\n",
      "g_step: 952, action: 0, reward: 1, loss: 10.472372055053711\n",
      "g_step: 953, action: 0, reward: 1, loss: 68.20922088623047\n",
      "g_step: 954, action: 0, reward: 1, loss: 14.218172073364258\n",
      "g_step: 955, action: 0, reward: 1, loss: 13.712287902832031\n",
      "g_step: 956, action: 0, reward: 1, loss: 12.123590469360352\n",
      "g_step: 957, action: 0, reward: 1, loss: 23.43675994873047\n",
      "g_step: 958, action: 0, reward: 1, loss: 10.814760208129883\n",
      "g_step: 959, action: 0, reward: 1, loss: 11.687200546264648\n",
      "g_step: 960, action: 0, reward: 1, loss: 45.42607116699219\n",
      "g_step: 961, action: 0, reward: 1, loss: 35.61907196044922\n",
      "g_step: 962, action: 0, reward: 1, loss: 12.017060279846191\n",
      "g_step: 963, action: 0, reward: 1, loss: 20.131587982177734\n",
      "g_step: 964, action: 0, reward: 1, loss: 19.58807373046875\n",
      "g_step: 965, action: 0, reward: 1, loss: 19.45501708984375\n",
      "g_step: 966, action: 0, reward: 1, loss: 7.554322242736816\n",
      "g_step: 967, action: 0, reward: 1, loss: 10.58532428741455\n",
      "g_step: 968, action: 0, reward: 1, loss: 12.55125617980957\n",
      "g_step: 969, action: 0, reward: 1, loss: 931.2459716796875\n",
      "g_step: 970, action: 0, reward: 1, loss: 48.44499588012695\n",
      "g_step: 971, action: 0, reward: 1, loss: 9.24860954284668\n",
      "g_step: 972, action: 0, reward: 1, loss: 28.105112075805664\n",
      "g_step: 973, action: 0, reward: 1, loss: 19.450916290283203\n",
      "g_step: 974, action: 0, reward: 1, loss: 23.267391204833984\n",
      "g_step: 975, action: 0, reward: 1, loss: 720.3450317382812\n",
      "g_step: 976, action: 0, reward: 1, loss: 13.39968490600586\n",
      "g_step: 977, action: 0, reward: 1, loss: 15.418827056884766\n",
      "g_step: 978, action: 0, reward: 1, loss: 15.465017318725586\n",
      "g_step: 979, action: 0, reward: 1, loss: 21.52975845336914\n",
      "g_step: 980, action: 0, reward: 1, loss: 75.20048522949219\n",
      "g_step: 981, action: 0, reward: 1, loss: 78.33200073242188\n",
      "g_step: 982, action: 0, reward: 1, loss: 20.01910400390625\n",
      "g_step: 983, action: 0, reward: 1, loss: 31.956008911132812\n",
      "g_step: 984, action: 0, reward: 1, loss: 540.4219360351562\n",
      "g_step: 985, action: 0, reward: 1, loss: 541.2444458007812\n",
      "g_step: 986, action: 1, reward: -3, loss: 11.229875564575195\n",
      "g_step: 987, action: 0, reward: 1, loss: 26.310314178466797\n",
      "g_step: 988, action: 0, reward: 1, loss: 21.480655670166016\n",
      "g_step: 989, action: 0, reward: 1, loss: 27.3283634185791\n",
      "g_step: 990, action: 0, reward: 1, loss: 15.502790451049805\n",
      "g_step: 991, action: 0, reward: 1, loss: 287.504638671875\n",
      "g_step: 992, action: 0, reward: 1, loss: 23.051956176757812\n",
      "g_step: 993, action: 0, reward: 1, loss: 112.3502197265625\n",
      "Episode 12, Total reward: 9, Total loss: 6130.618443489075, Epsilon: 0.009998812000000001\n",
      "g_step: 994, action: 0, reward: 1, loss: 17.629362106323242\n",
      "g_step: 995, action: 0, reward: 1, loss: 22.477394104003906\n",
      "g_step: 996, action: 0, reward: 1, loss: 59.36651611328125\n",
      "g_step: 997, action: 0, reward: 1, loss: 27.72090721130371\n",
      "g_step: 998, action: 0, reward: 1, loss: 37.657474517822266\n",
      "g_step: 999, action: 0, reward: 1, loss: 17.241981506347656\n",
      "g_step: 1000, action: 0, reward: 1, loss: 19.872987747192383\n",
      "g_step: 1001, action: 0, reward: 1, loss: 24.641090393066406\n",
      "g_step: 1002, action: 0, reward: 1, loss: 39.769012451171875\n",
      "g_step: 1003, action: 0, reward: 1, loss: 22.07780647277832\n",
      "g_step: 1004, action: 0, reward: 1, loss: 29.41335105895996\n",
      "g_step: 1005, action: 0, reward: 1, loss: 47.77098846435547\n",
      "g_step: 1006, action: 0, reward: 1, loss: 75.76773834228516\n",
      "g_step: 1007, action: 0, reward: 1, loss: 51.7309455871582\n",
      "g_step: 1008, action: 0, reward: 1, loss: 27.280399322509766\n",
      "g_step: 1009, action: 0, reward: 1, loss: 25.811525344848633\n",
      "g_step: 1010, action: 0, reward: 1, loss: 30.35968017578125\n",
      "g_step: 1011, action: 0, reward: 1, loss: 33.604278564453125\n",
      "g_step: 1012, action: 0, reward: 1, loss: 17.816478729248047\n",
      "g_step: 1013, action: 0, reward: 1, loss: 34.96373748779297\n",
      "g_step: 1014, action: 0, reward: 1, loss: 33.71476364135742\n",
      "g_step: 1015, action: 0, reward: 1, loss: 130.64599609375\n",
      "g_step: 1016, action: 0, reward: 1, loss: 28.848590850830078\n",
      "g_step: 1017, action: 0, reward: 1, loss: 37.76994323730469\n",
      "g_step: 1018, action: 0, reward: 1, loss: 21.29178237915039\n",
      "g_step: 1019, action: 0, reward: 1, loss: 25.406333923339844\n",
      "g_step: 1020, action: 0, reward: 1, loss: 15.573142051696777\n",
      "g_step: 1021, action: 0, reward: 1, loss: 51.35540008544922\n",
      "g_step: 1022, action: 0, reward: 1, loss: 16.205886840820312\n",
      "g_step: 1023, action: 0, reward: 1, loss: 33.54072570800781\n",
      "g_step: 1024, action: 0, reward: 1, loss: 24.668724060058594\n",
      "g_step: 1025, action: 0, reward: 1, loss: 27.741588592529297\n",
      "g_step: 1026, action: 0, reward: 1, loss: 19.111177444458008\n",
      "g_step: 1027, action: 0, reward: 1, loss: 23.754724502563477\n",
      "g_step: 1028, action: 0, reward: 1, loss: 20.29191017150879\n",
      "g_step: 1029, action: 0, reward: 1, loss: 13.127859115600586\n",
      "g_step: 1030, action: 0, reward: 1, loss: 54.17628479003906\n",
      "g_step: 1031, action: 0, reward: 1, loss: 24.142595291137695\n",
      "g_step: 1032, action: 0, reward: 1, loss: 12.553876876831055\n",
      "g_step: 1033, action: 0, reward: 1, loss: 39.694557189941406\n",
      "g_step: 1034, action: 0, reward: 1, loss: 13.681966781616211\n",
      "g_step: 1035, action: 0, reward: 1, loss: 15.598274230957031\n",
      "g_step: 1036, action: 0, reward: 1, loss: 22.897953033447266\n",
      "g_step: 1037, action: 0, reward: 1, loss: 28.53246307373047\n",
      "g_step: 1038, action: 0, reward: 1, loss: 13.82116985321045\n",
      "g_step: 1039, action: 0, reward: 1, loss: 12.674700736999512\n",
      "g_step: 1040, action: 0, reward: 1, loss: 12.774450302124023\n",
      "g_step: 1041, action: 0, reward: 1, loss: 13.166849136352539\n",
      "g_step: 1042, action: 0, reward: 1, loss: 16.086376190185547\n",
      "g_step: 1043, action: 0, reward: 1, loss: 28.427757263183594\n",
      "g_step: 1044, action: 0, reward: 1, loss: 17.66250228881836\n",
      "g_step: 1045, action: 0, reward: 1, loss: 14.448776245117188\n",
      "g_step: 1046, action: 0, reward: 1, loss: 23.81257438659668\n",
      "g_step: 1047, action: 0, reward: 1, loss: 27.016162872314453\n",
      "g_step: 1048, action: 0, reward: 1, loss: 18.810583114624023\n",
      "g_step: 1049, action: 0, reward: 1, loss: 23.71343994140625\n",
      "g_step: 1050, action: 0, reward: 1, loss: 10.327468872070312\n",
      "g_step: 1051, action: 0, reward: 1, loss: 16.55963134765625\n",
      "Episode 13, Total reward: 58, Total loss: 1646.6026182174683, Epsilon: 0.009998713000000001\n",
      "g_step: 1052, action: 0, reward: 1, loss: 17.327510833740234\n",
      "g_step: 1053, action: 0, reward: 1, loss: 15.774721145629883\n",
      "g_step: 1054, action: 0, reward: 1, loss: 21.571346282958984\n",
      "g_step: 1055, action: 0, reward: 1, loss: 21.945524215698242\n",
      "g_step: 1056, action: 0, reward: 1, loss: 15.917670249938965\n",
      "g_step: 1057, action: 0, reward: 1, loss: 38.67518615722656\n",
      "g_step: 1058, action: 0, reward: 1, loss: 26.72570037841797\n",
      "g_step: 1059, action: 0, reward: 1, loss: 24.290563583374023\n",
      "g_step: 1060, action: 0, reward: 1, loss: 12.781929969787598\n",
      "g_step: 1061, action: 0, reward: 1, loss: 21.44540023803711\n",
      "g_step: 1062, action: 0, reward: 1, loss: 22.043594360351562\n",
      "g_step: 1063, action: 0, reward: 1, loss: 25.862825393676758\n",
      "g_step: 1064, action: 0, reward: 1, loss: 17.60564422607422\n",
      "g_step: 1065, action: 0, reward: 1, loss: 19.65331268310547\n",
      "g_step: 1066, action: 0, reward: 1, loss: 25.4384765625\n",
      "g_step: 1067, action: 0, reward: 1, loss: 19.75040054321289\n",
      "g_step: 1068, action: 0, reward: 1, loss: 27.757823944091797\n",
      "g_step: 1069, action: 0, reward: 1, loss: 19.861888885498047\n",
      "g_step: 1070, action: 0, reward: 1, loss: 31.435028076171875\n",
      "g_step: 1071, action: 0, reward: 1, loss: 140.7032470703125\n",
      "g_step: 1072, action: 0, reward: 1, loss: 17.346696853637695\n",
      "g_step: 1073, action: 0, reward: 1, loss: 51.461788177490234\n",
      "g_step: 1074, action: 0, reward: 1, loss: 32.62916946411133\n",
      "g_step: 1075, action: 0, reward: 1, loss: 28.565387725830078\n",
      "g_step: 1076, action: 0, reward: 1, loss: 23.28226089477539\n",
      "g_step: 1077, action: 0, reward: 1, loss: 15.689640998840332\n",
      "g_step: 1078, action: 0, reward: 1, loss: 61.33997344970703\n",
      "g_step: 1079, action: 0, reward: 1, loss: 12.754827499389648\n",
      "g_step: 1080, action: 0, reward: 1, loss: 26.55586051940918\n",
      "g_step: 1081, action: 0, reward: 1, loss: 26.928525924682617\n",
      "g_step: 1082, action: 0, reward: 1, loss: 18.996036529541016\n",
      "g_step: 1083, action: 0, reward: 1, loss: 29.854610443115234\n",
      "g_step: 1084, action: 0, reward: 1, loss: 13.708635330200195\n",
      "g_step: 1085, action: 0, reward: 1, loss: 22.815868377685547\n",
      "g_step: 1086, action: 0, reward: 1, loss: 39.857948303222656\n",
      "g_step: 1087, action: 0, reward: 1, loss: 10.982120513916016\n",
      "g_step: 1088, action: 0, reward: 1, loss: 12.77363395690918\n",
      "g_step: 1089, action: 0, reward: 1, loss: 10.799736976623535\n",
      "g_step: 1090, action: 0, reward: 1, loss: 23.727088928222656\n",
      "g_step: 1091, action: 0, reward: 1, loss: 16.592533111572266\n",
      "g_step: 1092, action: 0, reward: 1, loss: 19.03052520751953\n",
      "g_step: 1093, action: 0, reward: 1, loss: 18.270334243774414\n",
      "g_step: 1094, action: 0, reward: 1, loss: 14.760967254638672\n",
      "g_step: 1095, action: 0, reward: 1, loss: 31.32914161682129\n",
      "g_step: 1096, action: 0, reward: 1, loss: 17.301679611206055\n",
      "g_step: 1097, action: 0, reward: 1, loss: 22.650897979736328\n",
      "g_step: 1098, action: 0, reward: 1, loss: 23.00300407409668\n",
      "g_step: 1099, action: 0, reward: 1, loss: 15.7543306350708\n",
      "g_step: 1100, action: 0, reward: 1, loss: 16.51870346069336\n",
      "g_step: 1101, action: 0, reward: 1, loss: 9.523746490478516\n",
      "g_step: 1102, action: 0, reward: 1, loss: 18.285537719726562\n",
      "g_step: 1103, action: 0, reward: 1, loss: 16.59728240966797\n",
      "g_step: 1104, action: 0, reward: 1, loss: 9.618705749511719\n",
      "g_step: 1105, action: 0, reward: 1, loss: 77.35137176513672\n",
      "g_step: 1106, action: 0, reward: 1, loss: 8.03367805480957\n",
      "g_step: 1107, action: 0, reward: 1, loss: 14.36292839050293\n",
      "g_step: 1108, action: 0, reward: 1, loss: 20.656085968017578\n",
      "Episode 14, Total reward: 57, Total loss: 1416.2790594100952, Epsilon: 0.009998614000000001\n",
      "g_step: 1109, action: 0, reward: 1, loss: 12.637983322143555\n",
      "g_step: 1110, action: 0, reward: 1, loss: 20.480241775512695\n",
      "g_step: 1111, action: 0, reward: 1, loss: 15.442571640014648\n",
      "g_step: 1112, action: 0, reward: 1, loss: 11.090560913085938\n",
      "g_step: 1113, action: 0, reward: 1, loss: 17.157121658325195\n",
      "g_step: 1114, action: 0, reward: 1, loss: 59.6133918762207\n",
      "g_step: 1115, action: 0, reward: 1, loss: 7.489564895629883\n",
      "g_step: 1116, action: 0, reward: 1, loss: 17.654476165771484\n",
      "g_step: 1117, action: 0, reward: 1, loss: 32.389408111572266\n",
      "g_step: 1118, action: 0, reward: 1, loss: 20.396907806396484\n",
      "g_step: 1119, action: 0, reward: 1, loss: 15.100845336914062\n",
      "g_step: 1120, action: 0, reward: 1, loss: 9.073841094970703\n",
      "g_step: 1121, action: 0, reward: 1, loss: 17.140348434448242\n",
      "g_step: 1122, action: 0, reward: 1, loss: 444.5941162109375\n",
      "g_step: 1123, action: 0, reward: 1, loss: 11.770692825317383\n",
      "g_step: 1124, action: 0, reward: 1, loss: 31.092403411865234\n",
      "g_step: 1125, action: 0, reward: 1, loss: 12.596731185913086\n",
      "g_step: 1126, action: 0, reward: 1, loss: 28.160308837890625\n",
      "g_step: 1127, action: 0, reward: 1, loss: 7.216127395629883\n",
      "g_step: 1128, action: 0, reward: 1, loss: 19.657958984375\n",
      "g_step: 1129, action: 0, reward: 1, loss: 17.632762908935547\n",
      "g_step: 1130, action: 0, reward: 1, loss: 20.54475212097168\n",
      "g_step: 1131, action: 0, reward: 1, loss: 16.17526626586914\n",
      "g_step: 1132, action: 0, reward: 1, loss: 20.077800750732422\n",
      "g_step: 1133, action: 0, reward: 1, loss: 181.2295684814453\n",
      "g_step: 1134, action: 0, reward: 1, loss: 18.458213806152344\n",
      "g_step: 1135, action: 0, reward: 1, loss: 11.595946311950684\n",
      "g_step: 1136, action: 0, reward: 1, loss: 24.620513916015625\n",
      "g_step: 1137, action: 0, reward: 1, loss: 27.84471893310547\n",
      "g_step: 1138, action: 0, reward: 1, loss: 10.779804229736328\n",
      "g_step: 1139, action: 0, reward: 1, loss: 18.156269073486328\n",
      "g_step: 1140, action: 0, reward: 1, loss: 12.469742774963379\n",
      "g_step: 1141, action: 0, reward: 1, loss: 18.156705856323242\n",
      "g_step: 1142, action: 0, reward: 1, loss: 11.13741683959961\n",
      "g_step: 1143, action: 0, reward: 1, loss: 39.58412551879883\n",
      "g_step: 1144, action: 0, reward: 1, loss: 16.973236083984375\n",
      "g_step: 1145, action: 0, reward: 1, loss: 8.553099632263184\n",
      "g_step: 1146, action: 0, reward: 1, loss: 13.846160888671875\n",
      "g_step: 1147, action: 0, reward: 1, loss: 18.17948341369629\n",
      "g_step: 1148, action: 0, reward: 1, loss: 67.18260192871094\n",
      "g_step: 1149, action: 0, reward: 1, loss: 15.925641059875488\n",
      "g_step: 1150, action: 0, reward: 1, loss: 21.573604583740234\n",
      "g_step: 1151, action: 0, reward: 1, loss: 15.56515884399414\n",
      "g_step: 1152, action: 0, reward: 1, loss: 21.185871124267578\n",
      "g_step: 1153, action: 0, reward: 1, loss: 25.921958923339844\n",
      "g_step: 1154, action: 0, reward: 1, loss: 21.41874122619629\n",
      "g_step: 1155, action: 0, reward: 1, loss: 11.894654273986816\n",
      "g_step: 1156, action: 0, reward: 1, loss: 16.27366065979004\n",
      "g_step: 1157, action: 0, reward: 1, loss: 17.620758056640625\n",
      "g_step: 1158, action: 0, reward: 1, loss: 12.394258499145508\n",
      "g_step: 1159, action: 0, reward: 1, loss: 13.795536041259766\n",
      "g_step: 1160, action: 0, reward: 1, loss: 23.979581832885742\n",
      "g_step: 1161, action: 0, reward: 1, loss: 26.35357666015625\n",
      "g_step: 1162, action: 0, reward: 1, loss: 17.943435668945312\n",
      "g_step: 1163, action: 0, reward: 1, loss: 30.059606552124023\n",
      "g_step: 1164, action: 0, reward: 1, loss: 25.39975929260254\n",
      "g_step: 1165, action: 0, reward: 1, loss: 17.31830596923828\n",
      "g_step: 1166, action: 0, reward: 1, loss: 18.393667221069336\n",
      "Episode 15, Total reward: 58, Total loss: 1736.971568107605, Epsilon: 0.009998515000000001\n",
      "g_step: 1167, action: 0, reward: 1, loss: 16.436492919921875\n",
      "g_step: 1168, action: 0, reward: 1, loss: 7.850358009338379\n",
      "g_step: 1169, action: 0, reward: 1, loss: 13.109376907348633\n",
      "g_step: 1170, action: 0, reward: 1, loss: 63.039283752441406\n",
      "g_step: 1171, action: 0, reward: 1, loss: 21.19375228881836\n",
      "g_step: 1172, action: 0, reward: 1, loss: 20.917728424072266\n",
      "g_step: 1173, action: 0, reward: 1, loss: 18.968307495117188\n",
      "g_step: 1174, action: 0, reward: 1, loss: 18.970727920532227\n",
      "g_step: 1175, action: 0, reward: 1, loss: 19.670333862304688\n",
      "g_step: 1176, action: 0, reward: 1, loss: 14.035233497619629\n",
      "g_step: 1177, action: 0, reward: 1, loss: 9.327688217163086\n",
      "g_step: 1178, action: 0, reward: 1, loss: 18.028968811035156\n",
      "g_step: 1179, action: 0, reward: 1, loss: 9.818464279174805\n",
      "g_step: 1180, action: 0, reward: 1, loss: 10.806532859802246\n",
      "g_step: 1181, action: 0, reward: 1, loss: 133.87086486816406\n",
      "g_step: 1182, action: 0, reward: 1, loss: 7.917092800140381\n",
      "g_step: 1183, action: 0, reward: 1, loss: 11.107288360595703\n",
      "g_step: 1184, action: 0, reward: 1, loss: 10.77598762512207\n",
      "g_step: 1185, action: 0, reward: 1, loss: 13.34749698638916\n",
      "g_step: 1186, action: 0, reward: 1, loss: 15.14073371887207\n",
      "g_step: 1187, action: 0, reward: 1, loss: 10.102147102355957\n",
      "g_step: 1188, action: 0, reward: 1, loss: 6.863864898681641\n",
      "g_step: 1189, action: 0, reward: 1, loss: 21.978641510009766\n",
      "g_step: 1190, action: 0, reward: 1, loss: 11.40074634552002\n",
      "g_step: 1191, action: 0, reward: 1, loss: 14.919843673706055\n",
      "g_step: 1192, action: 0, reward: 1, loss: 17.152423858642578\n",
      "g_step: 1193, action: 0, reward: 1, loss: 28.93328094482422\n",
      "g_step: 1194, action: 0, reward: 1, loss: 12.496400833129883\n",
      "g_step: 1195, action: 0, reward: 1, loss: 15.814367294311523\n",
      "g_step: 1196, action: 0, reward: 1, loss: 10.03987979888916\n",
      "g_step: 1197, action: 0, reward: 1, loss: 23.949047088623047\n",
      "g_step: 1198, action: 0, reward: 1, loss: 15.989592552185059\n",
      "g_step: 1199, action: 0, reward: 1, loss: 11.20400619506836\n",
      "g_step: 1200, action: 0, reward: 1, loss: 26.693195343017578\n",
      "g_step: 1201, action: 0, reward: 1, loss: 10.73951530456543\n",
      "g_step: 1202, action: 0, reward: 1, loss: 7.275417327880859\n",
      "g_step: 1203, action: 0, reward: 1, loss: 20.646875381469727\n",
      "g_step: 1204, action: 0, reward: 1, loss: 10.105968475341797\n",
      "g_step: 1205, action: 0, reward: 1, loss: 11.359724044799805\n",
      "g_step: 1206, action: 0, reward: 1, loss: 16.408411026000977\n",
      "g_step: 1207, action: 0, reward: 1, loss: 5.985202789306641\n",
      "g_step: 1208, action: 0, reward: 1, loss: 9.336151123046875\n",
      "g_step: 1209, action: 0, reward: 1, loss: 20.850095748901367\n",
      "g_step: 1210, action: 0, reward: 1, loss: 10.881051063537598\n",
      "g_step: 1211, action: 0, reward: 1, loss: 12.69561767578125\n",
      "g_step: 1212, action: 0, reward: 1, loss: 13.161954879760742\n",
      "g_step: 1213, action: 0, reward: 1, loss: 10.498504638671875\n",
      "g_step: 1214, action: 0, reward: 1, loss: 10.053146362304688\n",
      "g_step: 1215, action: 0, reward: 1, loss: 11.629762649536133\n",
      "g_step: 1216, action: 0, reward: 1, loss: 28.333309173583984\n",
      "g_step: 1217, action: 0, reward: 1, loss: 12.621667861938477\n",
      "g_step: 1218, action: 0, reward: 1, loss: 29.91030502319336\n",
      "g_step: 1219, action: 0, reward: 1, loss: 12.799605369567871\n",
      "g_step: 1220, action: 0, reward: 1, loss: 9.353432655334473\n",
      "g_step: 1221, action: 0, reward: 1, loss: 93.98348999023438\n",
      "g_step: 1222, action: 0, reward: 1, loss: 17.52634048461914\n",
      "g_step: 1223, action: 0, reward: 1, loss: 16.781898498535156\n",
      "Episode 16, Total reward: 57, Total loss: 1084.8075985908508, Epsilon: 0.009998416000000001\n",
      "g_step: 1224, action: 0, reward: 1, loss: 17.74454689025879\n",
      "g_step: 1225, action: 0, reward: 1, loss: 19.439685821533203\n",
      "g_step: 1226, action: 0, reward: 1, loss: 16.36168098449707\n",
      "g_step: 1227, action: 0, reward: 1, loss: 11.462604522705078\n",
      "g_step: 1228, action: 0, reward: 1, loss: 17.413192749023438\n",
      "g_step: 1229, action: 1, reward: -3, loss: 17.013813018798828\n",
      "g_step: 1230, action: 0, reward: 1, loss: 12.818571090698242\n",
      "g_step: 1231, action: 0, reward: 1, loss: 12.589653968811035\n",
      "g_step: 1232, action: 0, reward: 1, loss: 28.41318702697754\n",
      "g_step: 1233, action: 0, reward: 1, loss: 13.953465461730957\n",
      "g_step: 1234, action: 0, reward: 1, loss: 9.896528244018555\n",
      "g_step: 1235, action: 0, reward: 1, loss: 16.22189712524414\n",
      "g_step: 1236, action: 0, reward: 1, loss: 19.07434844970703\n",
      "g_step: 1237, action: 0, reward: 1, loss: 13.899347305297852\n",
      "g_step: 1238, action: 0, reward: 1, loss: 19.303030014038086\n",
      "g_step: 1239, action: 0, reward: 1, loss: 10.836994171142578\n",
      "g_step: 1240, action: 0, reward: 1, loss: 19.131282806396484\n",
      "g_step: 1241, action: 0, reward: 1, loss: 8.753555297851562\n",
      "g_step: 1242, action: 0, reward: 1, loss: 10.974958419799805\n",
      "g_step: 1243, action: 0, reward: 1, loss: 35.45762252807617\n",
      "g_step: 1244, action: 0, reward: 1, loss: 21.663423538208008\n",
      "g_step: 1245, action: 0, reward: 1, loss: 11.340986251831055\n",
      "g_step: 1246, action: 0, reward: 1, loss: 12.645417213439941\n",
      "g_step: 1247, action: 0, reward: 1, loss: 12.800029754638672\n",
      "g_step: 1248, action: 0, reward: 1, loss: 10.335455894470215\n",
      "g_step: 1249, action: 0, reward: 1, loss: 7.413516998291016\n",
      "g_step: 1250, action: 0, reward: 1, loss: 16.531827926635742\n",
      "g_step: 1251, action: 0, reward: 1, loss: 10.229808807373047\n",
      "g_step: 1252, action: 0, reward: 1, loss: 48.783512115478516\n",
      "g_step: 1253, action: 0, reward: 1, loss: 11.200334548950195\n",
      "g_step: 1254, action: 0, reward: 1, loss: 40.83871841430664\n",
      "g_step: 1255, action: 0, reward: 1, loss: 35.90450668334961\n",
      "g_step: 1256, action: 0, reward: 1, loss: 29.949443817138672\n",
      "g_step: 1257, action: 0, reward: 1, loss: 20.839237213134766\n",
      "g_step: 1258, action: 0, reward: 1, loss: 16.603986740112305\n",
      "g_step: 1259, action: 0, reward: 1, loss: 38.26545333862305\n",
      "g_step: 1260, action: 1, reward: -3, loss: 26.244464874267578\n",
      "g_step: 1261, action: 0, reward: 1, loss: 17.006328582763672\n",
      "g_step: 1262, action: 0, reward: 1, loss: 18.751827239990234\n",
      "g_step: 1263, action: 0, reward: 1, loss: 15.193370819091797\n",
      "g_step: 1264, action: 0, reward: 1, loss: 30.048185348510742\n",
      "g_step: 1265, action: 0, reward: 1, loss: 15.79180908203125\n",
      "g_step: 1266, action: 0, reward: 1, loss: 12.18508529663086\n",
      "g_step: 1267, action: 0, reward: 1, loss: 10.670001983642578\n",
      "g_step: 1268, action: 0, reward: 1, loss: 11.623346328735352\n",
      "g_step: 1269, action: 0, reward: 1, loss: 49.51527786254883\n",
      "g_step: 1270, action: 0, reward: 1, loss: 23.36834144592285\n",
      "g_step: 1271, action: 0, reward: 1, loss: 13.389496803283691\n",
      "g_step: 1272, action: 0, reward: 1, loss: 13.430120468139648\n",
      "g_step: 1273, action: 0, reward: 1, loss: 11.394998550415039\n",
      "g_step: 1274, action: 0, reward: 1, loss: 8.955671310424805\n",
      "g_step: 1275, action: 0, reward: 1, loss: 8.679584503173828\n",
      "g_step: 1276, action: 0, reward: 1, loss: 30.316959381103516\n",
      "g_step: 1277, action: 0, reward: 1, loss: 11.092286109924316\n",
      "g_step: 1278, action: 0, reward: 1, loss: 17.450138092041016\n",
      "g_step: 1279, action: 0, reward: 1, loss: 35.7288703918457\n",
      "Episode 17, Total reward: 48, Total loss: 1056.9417896270752, Epsilon: 0.009998317000000001\n",
      "g_step: 1280, action: 0, reward: 1, loss: 43.795989990234375\n",
      "g_step: 1281, action: 0, reward: 1, loss: 41.39061737060547\n",
      "g_step: 1282, action: 0, reward: 1, loss: 24.25808334350586\n",
      "g_step: 1283, action: 0, reward: 1, loss: 13.445049285888672\n",
      "g_step: 1284, action: 0, reward: 1, loss: 16.13700294494629\n",
      "g_step: 1285, action: 0, reward: 1, loss: 24.9508056640625\n",
      "g_step: 1286, action: 0, reward: 1, loss: 16.204082489013672\n",
      "g_step: 1287, action: 0, reward: 1, loss: 17.330841064453125\n",
      "g_step: 1288, action: 0, reward: 1, loss: 15.210224151611328\n",
      "g_step: 1289, action: 0, reward: 1, loss: 14.886021614074707\n",
      "g_step: 1290, action: 0, reward: 1, loss: 21.604171752929688\n",
      "g_step: 1291, action: 0, reward: 1, loss: 23.80709457397461\n",
      "g_step: 1292, action: 0, reward: 1, loss: 11.735885620117188\n",
      "g_step: 1293, action: 0, reward: 1, loss: 10.93151569366455\n",
      "g_step: 1294, action: 0, reward: 1, loss: 11.672632217407227\n",
      "g_step: 1295, action: 0, reward: 1, loss: 25.106090545654297\n",
      "g_step: 1296, action: 0, reward: 1, loss: 21.92613410949707\n",
      "g_step: 1297, action: 0, reward: 1, loss: 31.89767837524414\n",
      "g_step: 1298, action: 0, reward: 1, loss: 31.01778221130371\n",
      "g_step: 1299, action: 0, reward: 1, loss: 67.82831573486328\n",
      "g_step: 1300, action: 0, reward: 1, loss: 20.600605010986328\n",
      "g_step: 1301, action: 0, reward: 1, loss: 14.941822052001953\n",
      "g_step: 1302, action: 0, reward: 1, loss: 23.565597534179688\n",
      "g_step: 1303, action: 0, reward: 1, loss: 32.856361389160156\n",
      "g_step: 1304, action: 0, reward: 1, loss: 15.201685905456543\n",
      "g_step: 1305, action: 0, reward: 1, loss: 29.66781234741211\n",
      "g_step: 1306, action: 0, reward: 1, loss: 13.908509254455566\n",
      "g_step: 1307, action: 0, reward: 1, loss: 19.583955764770508\n",
      "g_step: 1308, action: 0, reward: 1, loss: 21.688648223876953\n",
      "g_step: 1309, action: 0, reward: 1, loss: 17.997724533081055\n",
      "g_step: 1310, action: 0, reward: 1, loss: 18.03877067565918\n",
      "g_step: 1311, action: 0, reward: 1, loss: 14.65250015258789\n",
      "g_step: 1312, action: 0, reward: 1, loss: 13.194011688232422\n",
      "g_step: 1313, action: 0, reward: 1, loss: 23.536991119384766\n",
      "g_step: 1314, action: 0, reward: 1, loss: 12.092994689941406\n",
      "g_step: 1315, action: 0, reward: 1, loss: 15.051607131958008\n",
      "g_step: 1316, action: 0, reward: 1, loss: 45.48019790649414\n",
      "g_step: 1317, action: 0, reward: 1, loss: 14.66180419921875\n",
      "g_step: 1318, action: 1, reward: -3, loss: 19.86077308654785\n",
      "g_step: 1319, action: 0, reward: 1, loss: 8.734514236450195\n",
      "g_step: 1320, action: 0, reward: 1, loss: 24.39679718017578\n",
      "g_step: 1321, action: 0, reward: 1, loss: 13.091129302978516\n",
      "g_step: 1322, action: 0, reward: 1, loss: 9.680091857910156\n",
      "g_step: 1323, action: 0, reward: 1, loss: 158.9380340576172\n",
      "g_step: 1324, action: 0, reward: 1, loss: 27.999832153320312\n",
      "g_step: 1325, action: 0, reward: 1, loss: 17.142822265625\n",
      "g_step: 1326, action: 0, reward: 1, loss: 13.954119682312012\n",
      "g_step: 1327, action: 0, reward: 1, loss: 7.7823333740234375\n",
      "g_step: 1328, action: 0, reward: 1, loss: 25.20722770690918\n",
      "g_step: 1329, action: 0, reward: 1, loss: 8.30476188659668\n",
      "g_step: 1330, action: 0, reward: 1, loss: 7.56153678894043\n",
      "g_step: 1331, action: 0, reward: 1, loss: 32.25617980957031\n",
      "g_step: 1332, action: 0, reward: 1, loss: 28.003459930419922\n",
      "g_step: 1333, action: 0, reward: 1, loss: 11.025192260742188\n",
      "g_step: 1334, action: 0, reward: 1, loss: 15.991922378540039\n",
      "g_step: 1335, action: 0, reward: 1, loss: 9.836873054504395\n",
      "g_step: 1336, action: 0, reward: 1, loss: 29.825754165649414\n",
      "g_step: 1337, action: 0, reward: 1, loss: 23.10942840576172\n",
      "Episode 18, Total reward: 54, Total loss: 1344.560401916504, Epsilon: 0.009998218000000001\n",
      "g_step: 1338, action: 0, reward: 1, loss: 18.081851959228516\n",
      "g_step: 1339, action: 0, reward: 1, loss: 21.668685913085938\n",
      "g_step: 1340, action: 0, reward: 1, loss: 53.173736572265625\n",
      "g_step: 1341, action: 0, reward: 1, loss: 15.395431518554688\n",
      "g_step: 1342, action: 0, reward: 1, loss: 12.22620964050293\n",
      "g_step: 1343, action: 0, reward: 1, loss: 20.00407600402832\n",
      "g_step: 1344, action: 0, reward: 1, loss: 13.569108963012695\n",
      "g_step: 1345, action: 0, reward: 1, loss: 13.132730484008789\n",
      "g_step: 1346, action: 0, reward: 1, loss: 14.07227611541748\n",
      "g_step: 1347, action: 0, reward: 1, loss: 8.486486434936523\n",
      "g_step: 1348, action: 0, reward: 1, loss: 15.774864196777344\n",
      "g_step: 1349, action: 0, reward: 1, loss: 13.212712287902832\n",
      "g_step: 1350, action: 0, reward: 1, loss: 12.333209991455078\n",
      "g_step: 1351, action: 0, reward: 1, loss: 13.886467933654785\n",
      "g_step: 1352, action: 0, reward: 1, loss: 22.870677947998047\n",
      "g_step: 1353, action: 0, reward: 1, loss: 10.952102661132812\n",
      "g_step: 1354, action: 0, reward: 1, loss: 10.682291030883789\n",
      "g_step: 1355, action: 0, reward: 1, loss: 15.840071678161621\n",
      "g_step: 1356, action: 0, reward: 1, loss: 11.550714492797852\n",
      "g_step: 1357, action: 0, reward: 1, loss: 8.885513305664062\n",
      "g_step: 1358, action: 0, reward: 1, loss: 33.03789520263672\n",
      "g_step: 1359, action: 0, reward: 1, loss: 23.606000900268555\n",
      "g_step: 1360, action: 0, reward: 1, loss: 22.16653060913086\n",
      "g_step: 1361, action: 0, reward: 1, loss: 11.799444198608398\n",
      "g_step: 1362, action: 0, reward: 1, loss: 22.352096557617188\n",
      "g_step: 1363, action: 0, reward: 1, loss: 14.909975051879883\n",
      "g_step: 1364, action: 0, reward: 1, loss: 20.164291381835938\n",
      "g_step: 1365, action: 0, reward: 1, loss: 19.277873992919922\n",
      "g_step: 1366, action: 0, reward: 1, loss: 29.562267303466797\n",
      "g_step: 1367, action: 0, reward: 1, loss: 45.80226135253906\n",
      "g_step: 1368, action: 0, reward: 1, loss: 14.662250518798828\n",
      "g_step: 1369, action: 0, reward: 1, loss: 13.113424301147461\n",
      "g_step: 1370, action: 0, reward: 1, loss: 10.378067016601562\n",
      "g_step: 1371, action: 0, reward: 1, loss: 8.739827156066895\n",
      "g_step: 1372, action: 0, reward: 1, loss: 19.724903106689453\n",
      "g_step: 1373, action: 0, reward: 1, loss: 13.249425888061523\n",
      "g_step: 1374, action: 0, reward: 1, loss: 24.249534606933594\n",
      "g_step: 1375, action: 0, reward: 1, loss: 33.89729690551758\n",
      "g_step: 1376, action: 0, reward: 1, loss: 8.579402923583984\n",
      "g_step: 1377, action: 0, reward: 1, loss: 26.447120666503906\n",
      "g_step: 1378, action: 0, reward: 1, loss: 39.65132141113281\n",
      "g_step: 1379, action: 0, reward: 1, loss: 11.805865287780762\n",
      "g_step: 1380, action: 0, reward: 1, loss: 18.0285587310791\n",
      "g_step: 1381, action: 0, reward: 1, loss: 11.659453392028809\n",
      "g_step: 1382, action: 0, reward: 1, loss: 12.174278259277344\n",
      "g_step: 1383, action: 0, reward: 1, loss: 17.198068618774414\n",
      "g_step: 1384, action: 0, reward: 1, loss: 6.253120422363281\n",
      "g_step: 1385, action: 0, reward: 1, loss: 33.95861053466797\n",
      "g_step: 1386, action: 0, reward: 1, loss: 14.937301635742188\n",
      "g_step: 1387, action: 0, reward: 1, loss: 22.541255950927734\n",
      "g_step: 1388, action: 0, reward: 1, loss: 12.004886627197266\n",
      "g_step: 1389, action: 0, reward: 1, loss: 13.411378860473633\n",
      "g_step: 1390, action: 0, reward: 1, loss: 13.980216979980469\n",
      "g_step: 1391, action: 0, reward: 1, loss: 13.201671600341797\n",
      "g_step: 1392, action: 0, reward: 1, loss: 23.496578216552734\n",
      "g_step: 1393, action: 0, reward: 1, loss: 32.288482666015625\n",
      "g_step: 1394, action: 0, reward: 1, loss: 31.547475814819336\n",
      "Episode 19, Total reward: 57, Total loss: 1069.657633781433, Epsilon: 0.009998119000000001\n",
      "g_step: 1395, action: 0, reward: 1, loss: 20.936267852783203\n",
      "g_step: 1396, action: 1, reward: -3, loss: 28.457019805908203\n",
      "g_step: 1397, action: 0, reward: 1, loss: 9.533014297485352\n",
      "g_step: 1398, action: 0, reward: 1, loss: 12.697840690612793\n",
      "g_step: 1399, action: 0, reward: 1, loss: 7.443385601043701\n",
      "g_step: 1400, action: 0, reward: 1, loss: 21.761112213134766\n",
      "g_step: 1401, action: 0, reward: 1, loss: 16.105409622192383\n",
      "g_step: 1402, action: 0, reward: 1, loss: 20.979856491088867\n",
      "g_step: 1403, action: 0, reward: 1, loss: 15.951169967651367\n",
      "g_step: 1404, action: 0, reward: 1, loss: 16.891725540161133\n",
      "g_step: 1405, action: 0, reward: 1, loss: 56.39023971557617\n",
      "g_step: 1406, action: 0, reward: 1, loss: 22.054807662963867\n",
      "g_step: 1407, action: 0, reward: 1, loss: 10.317289352416992\n",
      "g_step: 1408, action: 0, reward: 1, loss: 22.091163635253906\n",
      "g_step: 1409, action: 0, reward: 1, loss: 19.43575096130371\n",
      "g_step: 1410, action: 1, reward: -3, loss: 18.080930709838867\n",
      "g_step: 1411, action: 0, reward: 1, loss: 18.68423843383789\n",
      "g_step: 1412, action: 0, reward: 1, loss: 24.2215576171875\n",
      "g_step: 1413, action: 0, reward: 1, loss: 14.69745922088623\n",
      "g_step: 1414, action: 0, reward: 1, loss: 71.17375183105469\n",
      "g_step: 1415, action: 0, reward: 1, loss: 15.154698371887207\n",
      "g_step: 1416, action: 0, reward: 1, loss: 20.15549087524414\n",
      "g_step: 1417, action: 0, reward: 1, loss: 25.80845832824707\n",
      "g_step: 1418, action: 0, reward: 1, loss: 52.23393630981445\n",
      "g_step: 1419, action: 0, reward: 1, loss: 8.156144142150879\n",
      "g_step: 1420, action: 0, reward: 1, loss: 28.316932678222656\n",
      "g_step: 1421, action: 0, reward: 1, loss: 13.642265319824219\n",
      "g_step: 1422, action: 0, reward: 1, loss: 16.947654724121094\n",
      "g_step: 1423, action: 0, reward: 1, loss: 19.546161651611328\n",
      "g_step: 1424, action: 0, reward: 1, loss: 21.508380889892578\n",
      "g_step: 1425, action: 0, reward: 1, loss: 18.754547119140625\n",
      "g_step: 1426, action: 0, reward: 1, loss: 23.377826690673828\n",
      "g_step: 1427, action: 0, reward: 1, loss: 19.06231689453125\n",
      "g_step: 1428, action: 0, reward: 1, loss: 12.543163299560547\n",
      "g_step: 1429, action: 0, reward: 1, loss: 30.471094131469727\n",
      "g_step: 1430, action: 0, reward: 1, loss: 16.970199584960938\n",
      "g_step: 1431, action: 0, reward: 1, loss: 30.103670120239258\n",
      "g_step: 1432, action: 0, reward: 1, loss: 22.458383560180664\n",
      "g_step: 1433, action: 0, reward: 1, loss: 30.537919998168945\n",
      "g_step: 1434, action: 0, reward: 1, loss: 14.715553283691406\n",
      "g_step: 1435, action: 0, reward: 1, loss: 19.13334083557129\n",
      "g_step: 1436, action: 0, reward: 1, loss: 22.91167449951172\n",
      "g_step: 1437, action: 0, reward: 1, loss: 22.788196563720703\n",
      "g_step: 1438, action: 0, reward: 1, loss: 21.086851119995117\n",
      "g_step: 1439, action: 0, reward: 1, loss: 18.5460147857666\n",
      "g_step: 1440, action: 0, reward: 1, loss: 19.667879104614258\n",
      "g_step: 1441, action: 0, reward: 1, loss: 14.802597999572754\n",
      "g_step: 1442, action: 0, reward: 1, loss: 13.28544807434082\n",
      "g_step: 1443, action: 0, reward: 1, loss: 18.08172607421875\n",
      "g_step: 1444, action: 0, reward: 1, loss: 12.624303817749023\n",
      "g_step: 1445, action: 0, reward: 1, loss: 14.698613166809082\n",
      "g_step: 1446, action: 0, reward: 1, loss: 18.026962280273438\n",
      "g_step: 1447, action: 0, reward: 1, loss: 17.49396514892578\n",
      "g_step: 1448, action: 0, reward: 1, loss: 33.755210876464844\n",
      "g_step: 1449, action: 0, reward: 1, loss: 22.599807739257812\n",
      "g_step: 1450, action: 0, reward: 1, loss: 26.699865341186523\n",
      "g_step: 1451, action: 0, reward: 1, loss: 7.765186786651611\n",
      "g_step: 1452, action: 0, reward: 1, loss: 13.556941986083984\n",
      "Episode 20, Total reward: 50, Total loss: 1225.8933753967285, Epsilon: 0.009998020000000002\n",
      "g_step: 1453, action: 0, reward: 1, loss: 15.850359916687012\n",
      "g_step: 1454, action: 0, reward: 1, loss: 24.223670959472656\n",
      "g_step: 1455, action: 0, reward: 1, loss: 25.760848999023438\n",
      "g_step: 1456, action: 0, reward: 1, loss: 47.879573822021484\n",
      "g_step: 1457, action: 0, reward: 1, loss: 16.34998893737793\n",
      "g_step: 1458, action: 0, reward: 1, loss: 45.73491287231445\n",
      "g_step: 1459, action: 0, reward: 1, loss: 26.2214412689209\n",
      "g_step: 1460, action: 0, reward: 1, loss: 24.789260864257812\n",
      "g_step: 1461, action: 0, reward: 1, loss: 27.50379753112793\n",
      "g_step: 1462, action: 0, reward: 1, loss: 18.318466186523438\n",
      "g_step: 1463, action: 0, reward: 1, loss: 22.223846435546875\n",
      "g_step: 1464, action: 0, reward: 1, loss: 11.672760963439941\n",
      "g_step: 1465, action: 0, reward: 1, loss: 22.371421813964844\n",
      "g_step: 1466, action: 0, reward: 1, loss: 28.197219848632812\n",
      "g_step: 1467, action: 0, reward: 1, loss: 28.582061767578125\n",
      "g_step: 1468, action: 0, reward: 1, loss: 20.81831169128418\n",
      "g_step: 1469, action: 0, reward: 1, loss: 14.779857635498047\n",
      "g_step: 1470, action: 0, reward: 1, loss: 16.6729736328125\n",
      "g_step: 1471, action: 0, reward: 1, loss: 23.46622085571289\n",
      "g_step: 1472, action: 0, reward: 1, loss: 12.00887680053711\n",
      "g_step: 1473, action: 1, reward: -3, loss: 13.501530647277832\n",
      "g_step: 1474, action: 0, reward: 1, loss: 29.455467224121094\n",
      "g_step: 1475, action: 0, reward: 1, loss: 18.215553283691406\n",
      "g_step: 1476, action: 0, reward: 1, loss: 31.507156372070312\n",
      "g_step: 1477, action: 0, reward: 1, loss: 32.67237091064453\n",
      "g_step: 1478, action: 0, reward: 1, loss: 19.751083374023438\n",
      "g_step: 1479, action: 0, reward: 1, loss: 11.242818832397461\n",
      "g_step: 1480, action: 0, reward: 1, loss: 16.453968048095703\n",
      "g_step: 1481, action: 0, reward: 1, loss: 67.17227172851562\n",
      "g_step: 1482, action: 0, reward: 1, loss: 20.27119255065918\n",
      "g_step: 1483, action: 0, reward: 1, loss: 17.94232940673828\n",
      "g_step: 1484, action: 0, reward: 1, loss: 12.930357933044434\n",
      "g_step: 1485, action: 0, reward: 1, loss: 13.922103881835938\n",
      "g_step: 1486, action: 0, reward: 1, loss: 31.02103614807129\n",
      "g_step: 1487, action: 0, reward: 1, loss: 13.389824867248535\n",
      "g_step: 1488, action: 0, reward: 1, loss: 21.44133186340332\n",
      "g_step: 1489, action: 0, reward: 1, loss: 23.83711814880371\n",
      "g_step: 1490, action: 0, reward: 1, loss: 11.704151153564453\n",
      "g_step: 1491, action: 0, reward: 1, loss: 11.98054027557373\n",
      "g_step: 1492, action: 0, reward: 1, loss: 15.8971586227417\n",
      "g_step: 1493, action: 0, reward: 1, loss: 25.265941619873047\n",
      "g_step: 1494, action: 0, reward: 1, loss: 19.97539520263672\n",
      "g_step: 1495, action: 0, reward: 1, loss: 31.624343872070312\n",
      "g_step: 1496, action: 0, reward: 1, loss: 11.956348419189453\n",
      "g_step: 1497, action: 0, reward: 1, loss: 33.68979263305664\n",
      "g_step: 1498, action: 0, reward: 1, loss: 27.718664169311523\n",
      "g_step: 1499, action: 0, reward: 1, loss: 42.09894943237305\n",
      "g_step: 1500, action: 0, reward: 1, loss: 18.9656925201416\n",
      "g_step: 1501, action: 0, reward: 1, loss: 42.37855911254883\n",
      "g_step: 1502, action: 0, reward: 1, loss: 27.809242248535156\n",
      "g_step: 1503, action: 0, reward: 1, loss: 54.4986572265625\n",
      "g_step: 1504, action: 0, reward: 1, loss: 36.27394104003906\n",
      "g_step: 1505, action: 0, reward: 1, loss: 28.533329010009766\n",
      "g_step: 1506, action: 0, reward: 1, loss: 27.738868713378906\n",
      "g_step: 1507, action: 0, reward: 1, loss: 32.2204475402832\n",
      "g_step: 1508, action: 0, reward: 1, loss: 9.126906394958496\n",
      "g_step: 1509, action: 0, reward: 1, loss: 18.43096923828125\n",
      "g_step: 1510, action: 0, reward: 1, loss: 51.06928253173828\n",
      "Episode 21, Total reward: 54, Total loss: 1447.1105690002441, Epsilon: 0.009997921000000002\n",
      "g_step: 1511, action: 0, reward: 1, loss: 30.140766143798828\n",
      "g_step: 1512, action: 0, reward: 1, loss: 15.173316955566406\n",
      "g_step: 1513, action: 0, reward: 1, loss: 15.683980941772461\n",
      "g_step: 1514, action: 0, reward: 1, loss: 38.30557632446289\n",
      "g_step: 1515, action: 0, reward: 1, loss: 18.280271530151367\n",
      "g_step: 1516, action: 0, reward: 1, loss: 22.920320510864258\n",
      "g_step: 1517, action: 0, reward: 1, loss: 34.00879669189453\n",
      "g_step: 1518, action: 0, reward: 1, loss: 47.15123748779297\n",
      "g_step: 1519, action: 0, reward: 1, loss: 41.78849792480469\n",
      "g_step: 1520, action: 0, reward: 1, loss: 49.8048095703125\n",
      "g_step: 1521, action: 0, reward: 1, loss: 49.33977127075195\n",
      "g_step: 1522, action: 0, reward: 1, loss: 46.148529052734375\n",
      "g_step: 1523, action: 0, reward: 1, loss: 32.34577178955078\n",
      "g_step: 1524, action: 0, reward: 1, loss: 45.05218505859375\n",
      "g_step: 1525, action: 0, reward: 1, loss: 41.28059768676758\n",
      "g_step: 1526, action: 0, reward: 1, loss: 23.463459014892578\n",
      "g_step: 1527, action: 0, reward: 1, loss: 35.51704406738281\n",
      "g_step: 1528, action: 0, reward: 1, loss: 42.628604888916016\n",
      "g_step: 1529, action: 0, reward: 1, loss: 82.30787658691406\n",
      "g_step: 1530, action: 0, reward: 1, loss: 31.142391204833984\n",
      "g_step: 1531, action: 0, reward: 1, loss: 45.62908935546875\n",
      "g_step: 1532, action: 0, reward: 1, loss: 32.86354446411133\n",
      "g_step: 1533, action: 0, reward: 1, loss: 46.345855712890625\n",
      "g_step: 1534, action: 0, reward: 1, loss: 36.839263916015625\n",
      "g_step: 1535, action: 0, reward: 1, loss: 19.954273223876953\n",
      "g_step: 1536, action: 0, reward: 1, loss: 30.594562530517578\n",
      "g_step: 1537, action: 0, reward: 1, loss: 33.59615707397461\n",
      "g_step: 1538, action: 0, reward: 1, loss: 38.75890350341797\n",
      "g_step: 1539, action: 0, reward: 1, loss: 34.92646789550781\n",
      "g_step: 1540, action: 0, reward: 1, loss: 29.886075973510742\n",
      "g_step: 1541, action: 0, reward: 1, loss: 32.98445510864258\n",
      "g_step: 1542, action: 0, reward: 1, loss: 33.13502883911133\n",
      "g_step: 1543, action: 0, reward: 1, loss: 21.453536987304688\n",
      "g_step: 1544, action: 0, reward: 1, loss: 53.90449523925781\n",
      "g_step: 1545, action: 0, reward: 1, loss: 12.153339385986328\n",
      "g_step: 1546, action: 0, reward: 1, loss: 58.272178649902344\n",
      "g_step: 1547, action: 0, reward: 1, loss: 51.43169403076172\n",
      "g_step: 1548, action: 0, reward: 1, loss: 57.3095703125\n",
      "g_step: 1549, action: 1, reward: -3, loss: 17.37649917602539\n",
      "g_step: 1550, action: 0, reward: 1, loss: 23.565053939819336\n",
      "g_step: 1551, action: 0, reward: 1, loss: 250.79684448242188\n",
      "g_step: 1552, action: 0, reward: 1, loss: 35.87566375732422\n",
      "g_step: 1553, action: 0, reward: 1, loss: 31.84408187866211\n",
      "g_step: 1554, action: 0, reward: 1, loss: 44.84526443481445\n",
      "g_step: 1555, action: 0, reward: 1, loss: 26.59713363647461\n",
      "g_step: 1556, action: 0, reward: 1, loss: 19.762222290039062\n",
      "g_step: 1557, action: 0, reward: 1, loss: 70.64740753173828\n",
      "g_step: 1558, action: 0, reward: 1, loss: 38.34369659423828\n",
      "g_step: 1559, action: 0, reward: 1, loss: 36.88190841674805\n",
      "g_step: 1560, action: 0, reward: 1, loss: 39.12525939941406\n",
      "g_step: 1561, action: 0, reward: 1, loss: 42.65819549560547\n",
      "g_step: 1562, action: 0, reward: 1, loss: 81.37699890136719\n",
      "g_step: 1563, action: 0, reward: 1, loss: 54.559051513671875\n",
      "g_step: 1564, action: 0, reward: 1, loss: 24.799715042114258\n",
      "g_step: 1565, action: 0, reward: 1, loss: 30.13555908203125\n",
      "g_step: 1566, action: 0, reward: 1, loss: 35.50567626953125\n",
      "g_step: 1567, action: 0, reward: 1, loss: 39.38336181640625\n",
      "Episode 22, Total reward: 53, Total loss: 2356.601890563965, Epsilon: 0.009997822000000002\n",
      "g_step: 1568, action: 0, reward: 1, loss: 14.506633758544922\n",
      "g_step: 1569, action: 0, reward: 1, loss: 87.47429656982422\n",
      "g_step: 1570, action: 0, reward: 1, loss: 23.916797637939453\n",
      "g_step: 1571, action: 0, reward: 1, loss: 40.55958938598633\n",
      "g_step: 1572, action: 0, reward: 1, loss: 58.866485595703125\n",
      "g_step: 1573, action: 0, reward: 1, loss: 46.658199310302734\n",
      "g_step: 1574, action: 0, reward: 1, loss: 22.832693099975586\n",
      "g_step: 1575, action: 0, reward: 1, loss: 51.19713592529297\n",
      "g_step: 1576, action: 0, reward: 1, loss: 34.643428802490234\n",
      "g_step: 1577, action: 0, reward: 1, loss: 30.695634841918945\n",
      "g_step: 1578, action: 0, reward: 1, loss: 35.74262237548828\n",
      "g_step: 1579, action: 0, reward: 1, loss: 49.330848693847656\n",
      "g_step: 1580, action: 0, reward: 1, loss: 35.027198791503906\n",
      "g_step: 1581, action: 0, reward: 1, loss: 31.019302368164062\n",
      "g_step: 1582, action: 0, reward: 1, loss: 43.34233093261719\n",
      "g_step: 1583, action: 0, reward: 1, loss: 52.32307052612305\n",
      "g_step: 1584, action: 0, reward: 1, loss: 61.89881134033203\n",
      "g_step: 1585, action: 0, reward: 1, loss: 30.00756072998047\n",
      "g_step: 1586, action: 0, reward: 1, loss: 33.08152389526367\n",
      "g_step: 1587, action: 0, reward: 1, loss: 26.22182846069336\n",
      "g_step: 1588, action: 0, reward: 1, loss: 31.139110565185547\n",
      "g_step: 1589, action: 0, reward: 1, loss: 70.28244018554688\n",
      "g_step: 1590, action: 0, reward: 1, loss: 32.02915573120117\n",
      "g_step: 1591, action: 0, reward: 1, loss: 42.067726135253906\n",
      "g_step: 1592, action: 0, reward: 1, loss: 47.04762649536133\n",
      "g_step: 1593, action: 0, reward: 1, loss: 49.89426803588867\n",
      "g_step: 1594, action: 0, reward: 1, loss: 62.486473083496094\n",
      "g_step: 1595, action: 0, reward: 1, loss: 48.7469596862793\n",
      "g_step: 1596, action: 0, reward: 1, loss: 23.999074935913086\n",
      "g_step: 1597, action: 0, reward: 1, loss: 45.09618377685547\n",
      "g_step: 1598, action: 0, reward: 1, loss: 51.1002197265625\n",
      "g_step: 1599, action: 0, reward: 1, loss: 57.082603454589844\n",
      "g_step: 1600, action: 0, reward: 1, loss: 67.48983001708984\n",
      "g_step: 1601, action: 0, reward: 1, loss: 74.44682312011719\n",
      "g_step: 1602, action: 0, reward: 1, loss: 62.518890380859375\n",
      "g_step: 1603, action: 0, reward: 1, loss: 32.59319305419922\n",
      "g_step: 1604, action: 0, reward: 1, loss: 55.305091857910156\n",
      "g_step: 1605, action: 0, reward: 1, loss: 49.46476745605469\n",
      "g_step: 1606, action: 0, reward: 1, loss: 54.84062957763672\n",
      "g_step: 1607, action: 0, reward: 1, loss: 59.23072052001953\n",
      "g_step: 1608, action: 0, reward: 1, loss: 77.02262878417969\n",
      "g_step: 1609, action: 0, reward: 1, loss: 33.968406677246094\n",
      "g_step: 1610, action: 0, reward: 1, loss: 306.241943359375\n",
      "g_step: 1611, action: 0, reward: 1, loss: 22.01038360595703\n",
      "g_step: 1612, action: 0, reward: 1, loss: 91.21531677246094\n",
      "g_step: 1613, action: 0, reward: 1, loss: 157.0982666015625\n",
      "g_step: 1614, action: 0, reward: 1, loss: 89.35836791992188\n",
      "g_step: 1615, action: 0, reward: 1, loss: 51.793182373046875\n",
      "g_step: 1616, action: 0, reward: 1, loss: 56.38681411743164\n",
      "g_step: 1617, action: 0, reward: 1, loss: 66.04283142089844\n",
      "g_step: 1618, action: 0, reward: 1, loss: 60.682403564453125\n",
      "g_step: 1619, action: 0, reward: 1, loss: 36.80234146118164\n",
      "g_step: 1620, action: 0, reward: 1, loss: 33.299137115478516\n",
      "g_step: 1621, action: 0, reward: 1, loss: 111.88179779052734\n",
      "g_step: 1622, action: 0, reward: 1, loss: 72.22433471679688\n",
      "g_step: 1623, action: 0, reward: 1, loss: 35.97004318237305\n",
      "g_step: 1624, action: 0, reward: 1, loss: 72.08528137207031\n",
      "g_step: 1625, action: 0, reward: 1, loss: 70.23371887207031\n",
      "Episode 23, Total reward: 58, Total loss: 3270.524980545044, Epsilon: 0.009997723000000002\n",
      "g_step: 1626, action: 0, reward: 1, loss: 33.38861846923828\n",
      "g_step: 1627, action: 0, reward: 1, loss: 58.243438720703125\n",
      "g_step: 1628, action: 0, reward: 1, loss: 65.76538848876953\n",
      "g_step: 1629, action: 0, reward: 1, loss: 44.02037811279297\n",
      "g_step: 1630, action: 0, reward: 1, loss: 54.839046478271484\n",
      "g_step: 1631, action: 0, reward: 1, loss: 35.096519470214844\n",
      "g_step: 1632, action: 0, reward: 1, loss: 278.8820495605469\n",
      "g_step: 1633, action: 0, reward: 1, loss: 57.177345275878906\n",
      "g_step: 1634, action: 0, reward: 1, loss: 73.16141510009766\n",
      "g_step: 1635, action: 0, reward: 1, loss: 49.354251861572266\n",
      "g_step: 1636, action: 0, reward: 1, loss: 46.72075653076172\n",
      "g_step: 1637, action: 0, reward: 1, loss: 48.15796661376953\n",
      "g_step: 1638, action: 0, reward: 1, loss: 75.29705810546875\n",
      "g_step: 1639, action: 0, reward: 1, loss: 47.459991455078125\n",
      "g_step: 1640, action: 0, reward: 1, loss: 37.35088348388672\n",
      "g_step: 1641, action: 0, reward: 1, loss: 48.24085998535156\n",
      "g_step: 1642, action: 0, reward: 1, loss: 46.47123718261719\n",
      "g_step: 1643, action: 0, reward: 1, loss: 105.01044464111328\n",
      "g_step: 1644, action: 0, reward: 1, loss: 46.93879699707031\n",
      "g_step: 1645, action: 0, reward: 1, loss: 48.983558654785156\n",
      "g_step: 1646, action: 0, reward: 1, loss: 60.948490142822266\n",
      "g_step: 1647, action: 0, reward: 1, loss: 50.36717987060547\n",
      "g_step: 1648, action: 0, reward: 1, loss: 45.5256462097168\n",
      "g_step: 1649, action: 0, reward: 1, loss: 37.329856872558594\n",
      "g_step: 1650, action: 0, reward: 1, loss: 57.19602966308594\n",
      "g_step: 1651, action: 0, reward: 1, loss: 39.06786346435547\n",
      "g_step: 1652, action: 0, reward: 1, loss: 42.34468460083008\n",
      "g_step: 1653, action: 0, reward: 1, loss: 63.69693374633789\n",
      "g_step: 1654, action: 0, reward: 1, loss: 32.710113525390625\n",
      "g_step: 1655, action: 0, reward: 1, loss: 36.240299224853516\n",
      "g_step: 1656, action: 0, reward: 1, loss: 30.36707305908203\n",
      "g_step: 1657, action: 0, reward: 1, loss: 43.60603332519531\n",
      "g_step: 1658, action: 0, reward: 1, loss: 70.32682800292969\n",
      "g_step: 1659, action: 0, reward: 1, loss: 23.798458099365234\n",
      "g_step: 1660, action: 0, reward: 1, loss: 53.653133392333984\n",
      "g_step: 1661, action: 0, reward: 1, loss: 56.62474822998047\n",
      "g_step: 1662, action: 0, reward: 1, loss: 58.11591339111328\n",
      "g_step: 1663, action: 0, reward: 1, loss: 46.71015930175781\n",
      "g_step: 1664, action: 0, reward: 1, loss: 41.832305908203125\n",
      "g_step: 1665, action: 0, reward: 1, loss: 45.98783874511719\n",
      "g_step: 1666, action: 0, reward: 1, loss: 53.12348556518555\n",
      "g_step: 1667, action: 0, reward: 1, loss: 60.0650520324707\n",
      "g_step: 1668, action: 0, reward: 1, loss: 96.54955291748047\n",
      "g_step: 1669, action: 0, reward: 1, loss: 54.63628387451172\n",
      "g_step: 1670, action: 0, reward: 1, loss: 83.6341781616211\n",
      "g_step: 1671, action: 0, reward: 1, loss: 42.9869270324707\n",
      "g_step: 1672, action: 0, reward: 1, loss: 56.00556182861328\n",
      "g_step: 1673, action: 0, reward: 1, loss: 61.363914489746094\n",
      "g_step: 1674, action: 0, reward: 1, loss: 33.47441482543945\n",
      "g_step: 1675, action: 0, reward: 1, loss: 33.506866455078125\n",
      "g_step: 1676, action: 0, reward: 1, loss: 40.9753532409668\n",
      "g_step: 1677, action: 0, reward: 1, loss: 157.97113037109375\n",
      "g_step: 1678, action: 0, reward: 1, loss: 50.716064453125\n",
      "g_step: 1679, action: 0, reward: 1, loss: 33.3610725402832\n",
      "g_step: 1680, action: 0, reward: 1, loss: 23.75310516357422\n",
      "g_step: 1681, action: 0, reward: 1, loss: 50.04783630371094\n",
      "g_step: 1682, action: 0, reward: 1, loss: 33.4847412109375\n",
      "g_step: 1683, action: 0, reward: 1, loss: 49.496543884277344\n",
      "g_step: 1684, action: 0, reward: 1, loss: 38.65559387207031\n",
      "g_step: 1685, action: 0, reward: -100, loss: 59.405094146728516\n",
      "g_step: 1686, action: 0, reward: 1, loss: 37.15373229980469\n",
      "g_step: 1687, action: 0, reward: 1, loss: 37.35969543457031\n",
      "g_step: 1688, action: 0, reward: 1, loss: 36.382442474365234\n",
      "g_step: 1689, action: 0, reward: 1, loss: 37.421348571777344\n",
      "g_step: 1690, action: 0, reward: 1, loss: 31.77659797668457\n",
      "g_step: 1691, action: 0, reward: 1, loss: 24.69841766357422\n",
      "g_step: 1692, action: 0, reward: 1, loss: 42.76369094848633\n",
      "g_step: 1693, action: 0, reward: 1, loss: 36.274993896484375\n",
      "g_step: 1694, action: 0, reward: 1, loss: 77.47270202636719\n",
      "g_step: 1695, action: 0, reward: 1, loss: 33.730796813964844\n",
      "g_step: 1696, action: 0, reward: 1, loss: 55.76194763183594\n",
      "g_step: 1697, action: 0, reward: 1, loss: 34.58552551269531\n",
      "g_step: 1698, action: 0, reward: 1, loss: 21.108062744140625\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=124.0.6367.91)\nStacktrace:\n\tGetHandleVerifier [0x0104C113+48259]\n\t(No symbol) [0x00FDCA41]\n\t(No symbol) [0x00ED0A17]\n\t(No symbol) [0x00EAE02B]\n\t(No symbol) [0x00F3742E]\n\t(No symbol) [0x00F49476]\n\t(No symbol) [0x00F30B36]\n\t(No symbol) [0x00F0570D]\n\t(No symbol) [0x00F062CD]\n\tGetHandleVerifier [0x01306533+2908323]\n\tGetHandleVerifier [0x01343B4B+3159739]\n\tGetHandleVerifier [0x010E505B+674763]\n\tGetHandleVerifier [0x010EB21C+699788]\n\t(No symbol) [0x00FE6244]\n\t(No symbol) [0x00FE2298]\n\t(No symbol) [0x00FE242C]\n\t(No symbol) [0x00FD4BB0]\n\tBaseThreadInitThunk [0x75F87BA9+25]\n\tRtlInitializeExceptionChain [0x777FBE3B+107]\n\tRtlClearBits [0x777FBDBF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplayGame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mplayGame\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m game_state \u001b[38;5;241m=\u001b[39m Game_state(dino, game)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m :\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtrainNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     game\u001b[38;5;241m.\u001b[39mend()\n",
      "Cell \u001b[1;32mIn[13], line 19\u001b[0m, in \u001b[0;36mtrainNetwork\u001b[1;34m(model, game_state, optimizer, loss_fn, num_episodes, batch_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     17\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(FINAL_EPSILON, epsilon \u001b[38;5;241m-\u001b[39m (INITIAL_EPSILON \u001b[38;5;241m-\u001b[39m FINAL_EPSILON) \u001b[38;5;241m/\u001b[39m EXPLORE)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mgame_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_crashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     20\u001b[0m     global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m     action \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Random or best action based on epsilon\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36mDinoAgent.is_crashed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_crashed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_game\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_crashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36mGame.get_crashed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_crashed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn Runner.instance_.crashed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PROGRAMMING\\DinoGameAI\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:407\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    404\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    405\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\PROGRAMMING\\DinoGameAI\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\PROGRAMMING\\DinoGameAI\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=124.0.6367.91)\nStacktrace:\n\tGetHandleVerifier [0x0104C113+48259]\n\t(No symbol) [0x00FDCA41]\n\t(No symbol) [0x00ED0A17]\n\t(No symbol) [0x00EAE02B]\n\t(No symbol) [0x00F3742E]\n\t(No symbol) [0x00F49476]\n\t(No symbol) [0x00F30B36]\n\t(No symbol) [0x00F0570D]\n\t(No symbol) [0x00F062CD]\n\tGetHandleVerifier [0x01306533+2908323]\n\tGetHandleVerifier [0x01343B4B+3159739]\n\tGetHandleVerifier [0x010E505B+674763]\n\tGetHandleVerifier [0x010EB21C+699788]\n\t(No symbol) [0x00FE6244]\n\t(No symbol) [0x00FE2298]\n\t(No symbol) [0x00FE242C]\n\t(No symbol) [0x00FD4BB0]\n\tBaseThreadInitThunk [0x75F87BA9+25]\n\tRtlInitializeExceptionChain [0x777FBE3B+107]\n\tRtlClearBits [0x777FBDBF+191]\n"
     ]
    }
   ],
   "source": [
    "playGame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
